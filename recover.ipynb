{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68f40542",
   "metadata": {},
   "source": [
    "# Anonymous Feature Correlation Notebook\n",
    "\n",
    "This notebook correlates the anonymous features from `train.csv` with public, open-source data from **Yahoo Finance** and **FRED (Federal Reserve Economic Data)**.\n",
    "\n",
    "**Objective:** To de-anonymize the features by finding strong correlations with real-world indicators.\n",
    "\n",
    "**Logic:**\n",
    "1.  **Install** required libraries.\n",
    "2.  **Load Public Data:** Download 10+ years of daily data from Yahoo (`yfinance`) and FRED (`fredapi`).\n",
    "3.  **Load Anonymous Data:** Load the `train.csv` file.\n",
    "4.  **Map Dates:** Replicate the logic from the original notebook. We assume the `N` unique `date_id`s in `train.csv` map sequentially to the *last N* trading days of the S&P 500 (`^GSPC`) data.\n",
    "5.  **Merge Data:** Join all dataframes on the mapped `Date`.\n",
    "6.  **Calculate & Show Correlations:** Find the strongest (positive and negative) correlations between the anonymous and public features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e43b17c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 14 tickers from Yahoo Finance...\n",
      "Fetching 15 series from FRED...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74933/1999778491.py:75: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(list(tickers.values()), start=start, end=end, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Public Data Shape ---\n",
      "(5234, 262)\n",
      "\n",
      "--- Public Data Head ---\n",
      "shape: (5, 262)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ Date      ┆ S_BTC-USD ┆ P_CL=F    ┆ P_GC=F    ┆ … ┆ MOM_SMA_6 ┆ MOM_ROC_6 ┆ MOM_SMA_2 ┆ MOM_ROC_ │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ 3D_S_BAML ┆ 3D_S_BAML ┆ 52D_S_BAM ┆ 252D_S_B │\n",
      "│ date      ┆ f64       ┆ f64       ┆ f64       ┆   ┆ H0A0HYM2  ┆ H0A0HYM2  ┆ LH0A0HYM2 ┆ AMLH0A0H │\n",
      "│           ┆           ┆           ┆           ┆   ┆ ---       ┆ ---       ┆ ---       ┆ YM2      │\n",
      "│           ┆           ┆           ┆           ┆   ┆ f64       ┆ f64       ┆ f64       ┆ ---      │\n",
      "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ f64      │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 2010-01-0 ┆ null      ┆ 81.510002 ┆ 1117.6999 ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
      "│ 4         ┆           ┆           ┆ 51        ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 2010-01-0 ┆ null      ┆ 81.769997 ┆ 1118.0999 ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
      "│ 5         ┆           ┆           ┆ 76        ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 2010-01-0 ┆ null      ┆ 83.18     ┆ 1135.9000 ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
      "│ 6         ┆           ┆           ┆ 24        ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 2010-01-0 ┆ null      ┆ 82.660004 ┆ 1133.0999 ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
      "│ 7         ┆           ┆           ┆ 76        ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 2010-01-0 ┆ null      ┆ 82.75     ┆ 1138.1999 ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
      "│ 8         ┆           ┆           ┆ 51        ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Load Public Data ---\n",
    "import yfinance as yf\n",
    "from fredapi import Fred\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import dotenv\n",
    "\n",
    "# *** START OF UPDATE ***\n",
    "\n",
    "# --- Configuration ---\n",
    "START_DATE = \"2010-01-01\"\n",
    "END_DATE = datetime.now().strftime('%Y-%m-%d')\n",
    "FRED_API_KEY = dotenv.get_key(dotenv.find_dotenv(), \"FRED_API_KEY\")\n",
    "\n",
    "# Define tickers and FRED series IDs by category\n",
    "YFINANCE_TICKERS = {\n",
    "    # M* - Market Dynamics/Technical\n",
    "    'M_GSPC': '^GSPC',        # S&P 500 Index\n",
    "    'M_IXIC': '^IXIC',        # NASDAQ Composite\n",
    "    'M_DJI': '^DJI',          # Dow Jones Industrial Average\n",
    "    'M_RUT': '^RUT',          # Russell 2000\n",
    "\n",
    "    # V* - Volatility\n",
    "    'V_VIX': '^VIX',          # CBOE Volatility Index\n",
    "    'V_VXN': '^VXN',          # CBOE NASDAQ 100 Volatility Index\n",
    "\n",
    "    # P* - Price/Valuation\n",
    "    'P_GC=F': 'GC=F',         # Gold Futures\n",
    "    'P_CL=F': 'CL=F',         # Crude Oil Futures\n",
    "    'P_SI=F': 'SI=F',         # Silver Futures\n",
    "    'P_HG=F': 'HG=F',         # Copper Futures\n",
    "\n",
    "    # I* - Interest Rates (from Yahoo)\n",
    "    'I_FVX': '^FVX',          # Treasury Yield 5 Years\n",
    "    'I_TNX': '^TNX',          # CBOE Interest Rate 10 Year T Note\n",
    "    'I_TYX': '^TYX',          # Treasury Yield 30 Years\n",
    "    \n",
    "    # S* - Sentiment/Alternative\n",
    "    'S_BTC-USD': 'BTC-USD',   # Bitcoin\n",
    "}\n",
    "\n",
    "FRED_SERIES = {\n",
    "    # E* - Macro Economic\n",
    "    'E_GDP': 'GDP',                       # Gross Domestic Product\n",
    "    'E_UNRATE': 'UNRATE',                 # Unemployment Rate\n",
    "    'E_CPIAUCSL': 'CPIAUCSL',             # Consumer Price Index\n",
    "    'E_PPIACO': 'PPIACO',                 # Producer Price Index\n",
    "    'E_INDPRO': 'INDPRO',                 # Industrial Production Index\n",
    "    'E_PAYEMS': 'PAYEMS',                 # Non-Farm Payrolls\n",
    "    'E_ICSA': 'ICSA',                     # Initial Claims\n",
    "\n",
    "    # I* - Interest Rates\n",
    "    'I_DFF': 'DFF',                       # Federal Funds Effective Rate\n",
    "    'I_DTB3': 'DTB3',                     # 3-Month Treasury Bill\n",
    "    'I_DGS2': 'DGS2',                     # 2-Year Treasury Yield\n",
    "    'I_DGS10': 'DGS10',                   # 10-Year Treasury Yield\n",
    "    'I_T10Y2Y': 'T10Y2Y',                 # 10-Year vs 2-Year Treasury Spread\n",
    "\n",
    "    # V* - Volatility\n",
    "    'V_VIXCLS': 'VIXCLS',                 # VIX (from FRED)\n",
    "\n",
    "    # S* - Sentiment\n",
    "    'S_UMCSENT': 'UMCSENT',               # University of Michigan Consumer Sentiment\n",
    "    'S_BAMLH0A0HYM2': 'BAMLH0A0HYM2',    # BofA US High Yield Index Option-Adjusted Spread\n",
    "}\n",
    "\n",
    "# Define momentum periods (in days)\n",
    "MOMENTUM_PERIODS = [5, 21, 63, 252] # 1 week, 1 month, 1 quarter, 1 year\n",
    "\n",
    "# --- Data Fetching Functions ---\n",
    "def fetch_yfinance_data(tickers, start, end):\n",
    "    \"\"\"Fetches and processes data from Yahoo Finance.\"\"\"\n",
    "    print(f\"Fetching {len(tickers)} tickers from Yahoo Finance...\")\n",
    "    df = yf.download(list(tickers.values()), start=start, end=end, progress=False)\n",
    "    \n",
    "    # Use only 'Adj Close' and rename columns to custom names\n",
    "    df = df['Close']\n",
    "    df = df.rename(columns={v: k for k, v in tickers.items()})\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    return pl.from_pandas(df)\n",
    "\n",
    "def fetch_fred_data(series_ids, api_key, start, end):\n",
    "    \"\"\"Fetches and processes data from FRED.\"\"\"\n",
    "    print(f\"Fetching {len(series_ids)} series from FRED...\")\n",
    "    try:\n",
    "        fred = Fred(api_key=api_key)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error initializing Fred API: {e}\")\n",
    "        print(\"Please make sure you have set a valid FRED_API_KEY.\")\n",
    "        return pl.DataFrame()\n",
    "\n",
    "    # Fetch all series\n",
    "    df_list = []\n",
    "    for code, name in series_ids.items():\n",
    "        try:\n",
    "            s = fred.get_series(name, start_date=start, end_date=end)\n",
    "            s.name = code\n",
    "            df_list.append(s)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not fetch series {name} ({code}): {e}\")\n",
    "            \n",
    "    if not df_list:\n",
    "        print(\"No data fetched from FRED.\")\n",
    "        return pl.DataFrame()\n",
    "    \n",
    "    # Combine into a single DataFrame\n",
    "    df = pd.concat(df_list, axis=1).reset_index()\n",
    "    df = df.rename(columns={'index': 'Date'})\n",
    "    return pl.from_pandas(df)\n",
    "\n",
    "# --- Fetch and Process Data ---\n",
    "yf_data = fetch_yfinance_data(YFINANCE_TICKERS, START_DATE, END_DATE)\n",
    "fred_data = fetch_fred_data(FRED_SERIES, FRED_API_KEY, START_DATE, END_DATE)\n",
    "\n",
    "# Ensure Date columns are of the same type\n",
    "yf_data = yf_data.with_columns(pl.col(\"Date\").cast(pl.Date))\n",
    "if not fred_data.is_empty():\n",
    "    fred_data = fred_data.with_columns(pl.col(\"Date\").cast(pl.Date))\n",
    "\n",
    "    # Join the two public datasets\n",
    "    public_data = yf_data.join(fred_data, on='Date', how='left')\n",
    "else:\n",
    "    public_data = yf_data\n",
    "\n",
    "# Sort and forward-fill missing values (common for economic data)\n",
    "public_data = public_data.sort(\"Date\").fill_null(strategy='forward')\n",
    "\n",
    "# --- Calculate Momentum Features ---\n",
    "mom_features = []\n",
    "for col in public_data.columns:\n",
    "    if col != 'Date': # Don't calculate momentum on the date column\n",
    "        for period in MOMENTUM_PERIODS:\n",
    "            # Calculate rolling average (SMA)\n",
    "            sma_col_name = f\"MOM_SMA_{period}D_{col}\"\n",
    "            public_data = public_data.with_columns(\n",
    "                pl.col(col).rolling_mean(window_size=period).alias(sma_col_name)\n",
    "            )\n",
    "            \n",
    "            # Calculate Rate of Change (ROC)\n",
    "            roc_col_name = f\"MOM_ROC_{period}D_{col}\"\n",
    "            public_data = public_data.with_columns(\n",
    "                ((pl.col(col) / pl.col(col).shift(period)) - 1).alias(roc_col_name)\n",
    "            )\n",
    "            \n",
    "\n",
    "# Drop rows with nulls created by momentum calculations\n",
    "# public_data = public_data.drop_nulls()\n",
    "\n",
    "print(\"\\n--- Public Data Shape ---\")\n",
    "print(public_data.shape)\n",
    "print(\"\\n--- Public Data Head ---\")\n",
    "print(public_data.head())\n",
    "\n",
    "# *** END OF UPDATE ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2c34d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Anonymous Data Shape ---\n",
      "(7990, 98)\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Load Anonymous Data ---\n",
    "try:\n",
    "    # Load the training data\n",
    "    train = pl.read_csv('./kaggle/train.csv').slice(1000)\n",
    "    \n",
    "    # Get the feature columns (assuming they are named feature_0, feature_1, etc.)\n",
    "    ANONYMOUS_FEATURES = [col for col in train.columns if col not in ['id', 'date_id', 'target']]\n",
    "    \n",
    "    print(\"--- Anonymous Data Shape ---\")\n",
    "    print(train.shape)\n",
    "    \n",
    "    # Get unique date_ids to map\n",
    "    anonymous_date_ids = train.select('date_id').unique().sort('date_id')\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'train.csv' not found. Please make sure the file is in the correct directory.\")\n",
    "    train = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d9b6a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 85 string columns to convert: ['E1', 'E10', 'E11', 'E12', 'E13', 'E14', 'E15', 'E16', 'E17', 'E18', 'E19', 'E2', 'E20', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'M1', 'M10', 'M11', 'M12', 'M13', 'M14', 'M15', 'M16', 'M17', 'M18', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'P1', 'P10', 'P11', 'P12', 'P13', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'S1', 'S10', 'S11', 'S12', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'V1', 'V10', 'V11', 'V12', 'V13', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9']\n",
      "Found 7990 unique date_ids in train.csv.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Map Dates ---\n",
    "# Run the mapping\n",
    "SPY_DATE_PATH = './kaggle/spy-historical.csv'\n",
    "TRAIN_DATA_PATH = './kaggle/train.csv'\n",
    "df_spy = pl.read_csv(SPY_DATE_PATH)\n",
    "df_spy_date = df_spy.with_columns(pl.col(\"Date\").str.to_date().alias(\"Date\"))\n",
    "\n",
    "\n",
    "\"\"\"Loads train.csv and maps date_id to actual dates.\"\"\"\n",
    "\n",
    "df_train = pl.read_csv(TRAIN_DATA_PATH)\n",
    "df_train = df_train.slice(1000)\n",
    "#print(df_train.glimpse())\n",
    "anonymous_features = [col for col in df_train.columns if any(col.startswith(p) for p in ['M', 'E', 'I', 'P', 'V', 'S', 'D', 'MOM'])]\n",
    "string_features_to_convert = []\n",
    "\n",
    "for col_name in anonymous_features:\n",
    "    if df_train[col_name].dtype == pl.String:\n",
    "        string_features_to_convert.append(col_name)\n",
    "\n",
    "if string_features_to_convert:\n",
    "    print(f\"Found {len(string_features_to_convert)} string columns to convert: {string_features_to_convert}\")\n",
    "    \n",
    "    # 4. Convert them, turning bad values (like \"N/A\") into nulls\n",
    "    df_train = df_train.with_columns(\n",
    "        pl.col(string_features_to_convert).cast(pl.Float64, strict=False)\n",
    "    )\n",
    "\n",
    "# 1. Get unique, sorted date_ids from training data\n",
    "unique_date_ids = df_train[\"date_id\"].unique().sort()\n",
    "n_dates_train = len(unique_date_ids)\n",
    "print(f\"Found {n_dates_train} unique date_ids in train.csv.\")\n",
    "\n",
    "# 2. Get the *last N* trading days from our public SPY data\n",
    "# (This is the CRITICAL ASSUMPTION from your notebook)\n",
    "spy_ground_truth_dates = df_spy_date.sort(\"date_id\").tail(n_dates_train)[\"Date\"]\n",
    "\n",
    "if len(spy_ground_truth_dates) != n_dates_train:\n",
    "    print(\"Error: Mismatch in date counts. Cannot perform mapping.\")\n",
    "\n",
    "# 3. Create the mapping dataframe\n",
    "date_map = pl.DataFrame({\n",
    "    \"date_id\": unique_date_ids,\n",
    "    \"Date\": spy_ground_truth_dates\n",
    "})\n",
    "\n",
    "# print(\"Date mapping created. Example:\")\n",
    "# print(date_map.head(3))\n",
    "# print(\"...\")\n",
    "# print(date_map.tail(3))\n",
    "\n",
    "# 4. Join the map back to the training data\n",
    "df_train_with_dates = df_train.join(date_map, on=\"date_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4f0d611",
   "metadata": {},
   "outputs": [
    {
     "ename": "ColumnNotFoundError",
     "evalue": "\"^GSPC_Close\" not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mColumnNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m public_feature_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(YFINANCE_TICKERS\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(FRED_SERIES\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m     10\u001b[0m public_feature_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Close\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m YFINANCE_TICKERS\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01melse\u001b[39;00m col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m public_feature_cols]\n\u001b[0;32m---> 12\u001b[0m df_merged \u001b[38;5;241m=\u001b[39m df_merged\u001b[38;5;241m.\u001b[39mwith_columns(\n\u001b[1;32m     13\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcol(public_feature_cols)\u001b[38;5;241m.\u001b[39mforward_fill()\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Drop any remaining nulls (e.g., at the very start of the history)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m df_merged \u001b[38;5;241m=\u001b[39m df_merged\u001b[38;5;241m.\u001b[39mdrop_nulls()\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_311/lib/python3.11/site-packages/polars/dataframe/frame.py:10172\u001b[0m, in \u001b[0;36mDataFrame.with_columns\u001b[0;34m(self, *exprs, **named_exprs)\u001b[0m\n\u001b[1;32m  10045\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m  10046\u001b[0m \u001b[38;5;124;03mAdd columns to this DataFrame.\u001b[39;00m\n\u001b[1;32m  10047\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10165\u001b[0m \u001b[38;5;124;03m└─────┴──────┴───────┴──────┴───────┘\u001b[39;00m\n\u001b[1;32m  10166\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m  10167\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolars\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazyframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopt_flags\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QueryOptFlags\n\u001b[1;32m  10169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m  10170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy()\n\u001b[1;32m  10171\u001b[0m     \u001b[38;5;241m.\u001b[39mwith_columns(\u001b[38;5;241m*\u001b[39mexprs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnamed_exprs)\n\u001b[0;32m> 10172\u001b[0m     \u001b[38;5;241m.\u001b[39mcollect(optimizations\u001b[38;5;241m=\u001b[39mQueryOptFlags\u001b[38;5;241m.\u001b[39m_eager())\n\u001b[1;32m  10173\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_311/lib/python3.11/site-packages/polars/_utils/deprecation.py:97\u001b[0m, in \u001b[0;36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min-memory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstreaming\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_311/lib/python3.11/site-packages/polars/lazyframe/opt_flags.py:328\u001b[0m, in \u001b[0;36mforward_old_opt_flags.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m         optflags \u001b[38;5;241m=\u001b[39m cb(optflags, kwargs\u001b[38;5;241m.\u001b[39mpop(key))  \u001b[38;5;66;03m# type: ignore[no-untyped-call,unused-ignore]\u001b[39;00m\n\u001b[1;32m    327\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizations\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m optflags\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_311/lib/python3.11/site-packages/polars/lazyframe/frame.py:2415\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, optimizations, **_kwargs)\u001b[0m\n\u001b[1;32m   2413\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2414\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(ldf\u001b[38;5;241m.\u001b[39mcollect(engine, callback))\n",
      "\u001b[0;31mColumnNotFoundError\u001b[0m: \"^GSPC_Close\" not found"
     ]
    }
   ],
   "source": [
    "# --- 5. Merge Data ---\n",
    "master_df = None\n",
    "\n",
    "df_merged = df_train_with_dates.join(\n",
    "    public_data, on=\"Date\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Forward-fill nulls in public data (especially for FRED data)\n",
    "public_feature_cols = list(YFINANCE_TICKERS.values()) + list(FRED_SERIES.values())\n",
    "public_feature_cols = [f\"{col}_Close\" if col in YFINANCE_TICKERS.values() else col for col in public_feature_cols]\n",
    "\n",
    "df_merged = df_merged.with_columns(\n",
    "    pl.col(public_feature_cols).forward_fill()\n",
    ")\n",
    "\n",
    "# Drop any remaining nulls (e.g., at the very start of the history)\n",
    "df_merged = df_merged.drop_nulls()\n",
    "\n",
    "print(\"Master dataframe created. Shape:\", df_merged.shape)\n",
    "print(df_merged.tail())\n",
    "df_numeric_features = df_merged.select([pl.selectors.numeric()])\n",
    "print(f\"\\nNumeric features dataframe shape: {df_numeric_features.shape}\")\n",
    "\n",
    "master_df = df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "670aa25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anonymous features (94): ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'E1', 'E10', 'E11', 'E12', 'E13', 'E14', 'E15', 'E16', 'E17', 'E18', 'E19', 'E2', 'E20', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'M1', 'M10', 'M11', 'M12', 'M13', 'M14', 'M15', 'M16', 'M17', 'M18', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'P1', 'P10', 'P11', 'P12', 'P13', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'S1', 'S10', 'S11', 'S12', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'V1', 'V10', 'V11', 'V12', 'V13', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9']\n",
      "Public features (261): ['S_BTC-USD', 'P_CL=F', 'P_GC=F', 'P_HG=F', 'P_SI=F', 'M_DJI', 'I_FVX', 'M_GSPC', 'M_IXIC', 'M_RUT', 'I_TNX', 'I_TYX', 'V_VIX', 'V_VXN', 'E_GDP', 'E_UNRATE', 'E_CPIAUCSL', 'E_PPIACO', 'E_INDPRO', 'E_PAYEMS', 'E_ICSA', 'I_DFF', 'I_DTB3', 'I_DGS2', 'I_DGS10', 'I_T10Y2Y', 'V_VIXCLS', 'S_UMCSENT', 'S_BAMLH0A0HYM2', 'MOM_SMA_5D_S_BTC-USD', 'MOM_ROC_5D_S_BTC-USD', 'MOM_SMA_21D_S_BTC-USD', 'MOM_ROC_21D_S_BTC-USD', 'MOM_SMA_63D_S_BTC-USD', 'MOM_ROC_63D_S_BTC-USD', 'MOM_SMA_252D_S_BTC-USD', 'MOM_ROC_252D_S_BTC-USD', 'MOM_SMA_5D_P_CL=F', 'MOM_ROC_5D_P_CL=F', 'MOM_SMA_21D_P_CL=F', 'MOM_ROC_21D_P_CL=F', 'MOM_SMA_63D_P_CL=F', 'MOM_ROC_63D_P_CL=F', 'MOM_SMA_252D_P_CL=F', 'MOM_ROC_252D_P_CL=F', 'MOM_SMA_5D_P_GC=F', 'MOM_ROC_5D_P_GC=F', 'MOM_SMA_21D_P_GC=F', 'MOM_ROC_21D_P_GC=F', 'MOM_SMA_63D_P_GC=F', 'MOM_ROC_63D_P_GC=F', 'MOM_SMA_252D_P_GC=F', 'MOM_ROC_252D_P_GC=F', 'MOM_SMA_5D_P_HG=F', 'MOM_ROC_5D_P_HG=F', 'MOM_SMA_21D_P_HG=F', 'MOM_ROC_21D_P_HG=F', 'MOM_SMA_63D_P_HG=F', 'MOM_ROC_63D_P_HG=F', 'MOM_SMA_252D_P_HG=F', 'MOM_ROC_252D_P_HG=F', 'MOM_SMA_5D_P_SI=F', 'MOM_ROC_5D_P_SI=F', 'MOM_SMA_21D_P_SI=F', 'MOM_ROC_21D_P_SI=F', 'MOM_SMA_63D_P_SI=F', 'MOM_ROC_63D_P_SI=F', 'MOM_SMA_252D_P_SI=F', 'MOM_ROC_252D_P_SI=F', 'MOM_SMA_5D_M_DJI', 'MOM_ROC_5D_M_DJI', 'MOM_SMA_21D_M_DJI', 'MOM_ROC_21D_M_DJI', 'MOM_SMA_63D_M_DJI', 'MOM_ROC_63D_M_DJI', 'MOM_SMA_252D_M_DJI', 'MOM_ROC_252D_M_DJI', 'MOM_SMA_5D_I_FVX', 'MOM_ROC_5D_I_FVX', 'MOM_SMA_21D_I_FVX', 'MOM_ROC_21D_I_FVX', 'MOM_SMA_63D_I_FVX', 'MOM_ROC_63D_I_FVX', 'MOM_SMA_252D_I_FVX', 'MOM_ROC_252D_I_FVX', 'MOM_SMA_5D_M_GSPC', 'MOM_ROC_5D_M_GSPC', 'MOM_SMA_21D_M_GSPC', 'MOM_ROC_21D_M_GSPC', 'MOM_SMA_63D_M_GSPC', 'MOM_ROC_63D_M_GSPC', 'MOM_SMA_252D_M_GSPC', 'MOM_ROC_252D_M_GSPC', 'MOM_SMA_5D_M_IXIC', 'MOM_ROC_5D_M_IXIC', 'MOM_SMA_21D_M_IXIC', 'MOM_ROC_21D_M_IXIC', 'MOM_SMA_63D_M_IXIC', 'MOM_ROC_63D_M_IXIC', 'MOM_SMA_252D_M_IXIC', 'MOM_ROC_252D_M_IXIC', 'MOM_SMA_5D_M_RUT', 'MOM_ROC_5D_M_RUT', 'MOM_SMA_21D_M_RUT', 'MOM_ROC_21D_M_RUT', 'MOM_SMA_63D_M_RUT', 'MOM_ROC_63D_M_RUT', 'MOM_SMA_252D_M_RUT', 'MOM_ROC_252D_M_RUT', 'MOM_SMA_5D_I_TNX', 'MOM_ROC_5D_I_TNX', 'MOM_SMA_21D_I_TNX', 'MOM_ROC_21D_I_TNX', 'MOM_SMA_63D_I_TNX', 'MOM_ROC_63D_I_TNX', 'MOM_SMA_252D_I_TNX', 'MOM_ROC_252D_I_TNX', 'MOM_SMA_5D_I_TYX', 'MOM_ROC_5D_I_TYX', 'MOM_SMA_21D_I_TYX', 'MOM_ROC_21D_I_TYX', 'MOM_SMA_63D_I_TYX', 'MOM_ROC_63D_I_TYX', 'MOM_SMA_252D_I_TYX', 'MOM_ROC_252D_I_TYX', 'MOM_SMA_5D_V_VIX', 'MOM_ROC_5D_V_VIX', 'MOM_SMA_21D_V_VIX', 'MOM_ROC_21D_V_VIX', 'MOM_SMA_63D_V_VIX', 'MOM_ROC_63D_V_VIX', 'MOM_SMA_252D_V_VIX', 'MOM_ROC_252D_V_VIX', 'MOM_SMA_5D_V_VXN', 'MOM_ROC_5D_V_VXN', 'MOM_SMA_21D_V_VXN', 'MOM_ROC_21D_V_VXN', 'MOM_SMA_63D_V_VXN', 'MOM_ROC_63D_V_VXN', 'MOM_SMA_252D_V_VXN', 'MOM_ROC_252D_V_VXN', 'MOM_SMA_5D_E_GDP', 'MOM_ROC_5D_E_GDP', 'MOM_SMA_21D_E_GDP', 'MOM_ROC_21D_E_GDP', 'MOM_SMA_63D_E_GDP', 'MOM_ROC_63D_E_GDP', 'MOM_SMA_252D_E_GDP', 'MOM_ROC_252D_E_GDP', 'MOM_SMA_5D_E_UNRATE', 'MOM_ROC_5D_E_UNRATE', 'MOM_SMA_21D_E_UNRATE', 'MOM_ROC_21D_E_UNRATE', 'MOM_SMA_63D_E_UNRATE', 'MOM_ROC_63D_E_UNRATE', 'MOM_SMA_252D_E_UNRATE', 'MOM_ROC_252D_E_UNRATE', 'MOM_SMA_5D_E_CPIAUCSL', 'MOM_ROC_5D_E_CPIAUCSL', 'MOM_SMA_21D_E_CPIAUCSL', 'MOM_ROC_21D_E_CPIAUCSL', 'MOM_SMA_63D_E_CPIAUCSL', 'MOM_ROC_63D_E_CPIAUCSL', 'MOM_SMA_252D_E_CPIAUCSL', 'MOM_ROC_252D_E_CPIAUCSL', 'MOM_SMA_5D_E_PPIACO', 'MOM_ROC_5D_E_PPIACO', 'MOM_SMA_21D_E_PPIACO', 'MOM_ROC_21D_E_PPIACO', 'MOM_SMA_63D_E_PPIACO', 'MOM_ROC_63D_E_PPIACO', 'MOM_SMA_252D_E_PPIACO', 'MOM_ROC_252D_E_PPIACO', 'MOM_SMA_5D_E_INDPRO', 'MOM_ROC_5D_E_INDPRO', 'MOM_SMA_21D_E_INDPRO', 'MOM_ROC_21D_E_INDPRO', 'MOM_SMA_63D_E_INDPRO', 'MOM_ROC_63D_E_INDPRO', 'MOM_SMA_252D_E_INDPRO', 'MOM_ROC_252D_E_INDPRO', 'MOM_SMA_5D_E_PAYEMS', 'MOM_ROC_5D_E_PAYEMS', 'MOM_SMA_21D_E_PAYEMS', 'MOM_ROC_21D_E_PAYEMS', 'MOM_SMA_63D_E_PAYEMS', 'MOM_ROC_63D_E_PAYEMS', 'MOM_SMA_252D_E_PAYEMS', 'MOM_ROC_252D_E_PAYEMS', 'MOM_SMA_5D_E_ICSA', 'MOM_ROC_5D_E_ICSA', 'MOM_SMA_21D_E_ICSA', 'MOM_ROC_21D_E_ICSA', 'MOM_SMA_63D_E_ICSA', 'MOM_ROC_63D_E_ICSA', 'MOM_SMA_252D_E_ICSA', 'MOM_ROC_252D_E_ICSA', 'MOM_SMA_5D_I_DFF', 'MOM_ROC_5D_I_DFF', 'MOM_SMA_21D_I_DFF', 'MOM_ROC_21D_I_DFF', 'MOM_SMA_63D_I_DFF', 'MOM_ROC_63D_I_DFF', 'MOM_SMA_252D_I_DFF', 'MOM_ROC_252D_I_DFF', 'MOM_SMA_5D_I_DTB3', 'MOM_ROC_5D_I_DTB3', 'MOM_SMA_21D_I_DTB3', 'MOM_ROC_21D_I_DTB3', 'MOM_SMA_63D_I_DTB3', 'MOM_ROC_63D_I_DTB3', 'MOM_SMA_252D_I_DTB3', 'MOM_ROC_252D_I_DTB3', 'MOM_SMA_5D_I_DGS2', 'MOM_ROC_5D_I_DGS2', 'MOM_SMA_21D_I_DGS2', 'MOM_ROC_21D_I_DGS2', 'MOM_SMA_63D_I_DGS2', 'MOM_ROC_63D_I_DGS2', 'MOM_SMA_252D_I_DGS2', 'MOM_ROC_252D_I_DGS2', 'MOM_SMA_5D_I_DGS10', 'MOM_ROC_5D_I_DGS10', 'MOM_SMA_21D_I_DGS10', 'MOM_ROC_21D_I_DGS10', 'MOM_SMA_63D_I_DGS10', 'MOM_ROC_63D_I_DGS10', 'MOM_SMA_252D_I_DGS10', 'MOM_ROC_252D_I_DGS10', 'MOM_SMA_5D_I_T10Y2Y', 'MOM_ROC_5D_I_T10Y2Y', 'MOM_SMA_21D_I_T10Y2Y', 'MOM_ROC_21D_I_T10Y2Y', 'MOM_SMA_63D_I_T10Y2Y', 'MOM_ROC_63D_I_T10Y2Y', 'MOM_SMA_252D_I_T10Y2Y', 'MOM_ROC_252D_I_T10Y2Y', 'MOM_SMA_5D_V_VIXCLS', 'MOM_ROC_5D_V_VIXCLS', 'MOM_SMA_21D_V_VIXCLS', 'MOM_ROC_21D_V_VIXCLS', 'MOM_SMA_63D_V_VIXCLS', 'MOM_ROC_63D_V_VIXCLS', 'MOM_SMA_252D_V_VIXCLS', 'MOM_ROC_252D_V_VIXCLS', 'MOM_SMA_5D_S_UMCSENT', 'MOM_ROC_5D_S_UMCSENT', 'MOM_SMA_21D_S_UMCSENT', 'MOM_ROC_21D_S_UMCSENT', 'MOM_SMA_63D_S_UMCSENT', 'MOM_ROC_63D_S_UMCSENT', 'MOM_SMA_252D_S_UMCSENT', 'MOM_ROC_252D_S_UMCSENT', 'MOM_SMA_5D_S_BAMLH0A0HYM2', 'MOM_ROC_5D_S_BAMLH0A0HYM2', 'MOM_SMA_21D_S_BAMLH0A0HYM2', 'MOM_ROC_21D_S_BAMLH0A0HYM2', 'MOM_SMA_63D_S_BAMLH0A0HYM2', 'MOM_ROC_63D_S_BAMLH0A0HYM2', 'MOM_SMA_252D_S_BAMLH0A0HYM2', 'MOM_ROC_252D_S_BAMLH0A0HYM2']\n",
      "Correlating 94 anonymous features with 261 public features...\n",
      "\n",
      "--- Top 30 Most Correlated Feature Pairs --- (Positive or Negative)\n",
      "shape: (30, 4)\n",
      "┌───────────────────┬────────────────┬─────────────┬─────────────────┐\n",
      "│ anonymous_feature ┆ public_feature ┆ correlation ┆ abs_correlation │\n",
      "│ ---               ┆ ---            ┆ ---         ┆ ---             │\n",
      "│ str               ┆ str            ┆ f64         ┆ f64             │\n",
      "╞═══════════════════╪════════════════╪═════════════╪═════════════════╡\n",
      "│ D1                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D2                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D3                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D4                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D5                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ …                 ┆ …              ┆ …           ┆ …               │\n",
      "│ E6                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ E7                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ E8                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ E9                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ I1                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "└───────────────────┴────────────────┴─────────────┴─────────────────┘\n",
      "\n",
      "--- Top 10 Positive Correlations ---\n",
      "shape: (10, 4)\n",
      "┌───────────────────┬────────────────┬─────────────┬─────────────────┐\n",
      "│ anonymous_feature ┆ public_feature ┆ correlation ┆ abs_correlation │\n",
      "│ ---               ┆ ---            ┆ ---         ┆ ---             │\n",
      "│ str               ┆ str            ┆ f64         ┆ f64             │\n",
      "╞═══════════════════╪════════════════╪═════════════╪═════════════════╡\n",
      "│ D1                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D2                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D3                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D4                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D5                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D6                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D7                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D8                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D9                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ E1                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "└───────────────────┴────────────────┴─────────────┴─────────────────┘\n",
      "\n",
      "--- Top 10 Negative Correlations ---\n",
      "shape: (10, 4)\n",
      "┌───────────────────┬────────────────┬─────────────┬─────────────────┐\n",
      "│ anonymous_feature ┆ public_feature ┆ correlation ┆ abs_correlation │\n",
      "│ ---               ┆ ---            ┆ ---         ┆ ---             │\n",
      "│ str               ┆ str            ┆ f64         ┆ f64             │\n",
      "╞═══════════════════╪════════════════╪═════════════╪═════════════════╡\n",
      "│ D1                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D2                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D3                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D4                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D5                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D6                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D7                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D8                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ D9                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "│ E1                ┆ S_BTC-USD      ┆ NaN         ┆ NaN             │\n",
      "└───────────────────┴────────────────┴─────────────┴─────────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/numpy/core/_methods.py:118: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/tmp/ipykernel_74933/3137077397.py:32: DeprecationWarning: `DataFrame.melt` is deprecated; use `DataFrame.unpivot` instead, with `index` instead of `id_vars` and `on` instead of `value_vars`\n",
      "  corr_long = corr_subset.melt(\n"
     ]
    }
   ],
   "source": [
    "if 'df_merged' in locals() and df_merged is not None:\n",
    "    # Define our two feature groups\n",
    "    public_features = public_data.columns[1:]  # Exclude 'Date' column\n",
    "    #anonymous_features = [col for col in df_numeric_features.columns if col not in public_features and any(col.startswith(p) for p in ['M', 'E', 'I', 'P', 'V', 'S', 'D', 'MOM'])]\n",
    "\n",
    "    all_features = anonymous_features + public_features\n",
    "\n",
    "    print(f\"\\nAnonymous features ({len(anonymous_features)}): {anonymous_features}\")\n",
    "    print(f\"Public features ({len(public_features)}): {public_features}\")\n",
    "    \n",
    "    print(f\"Correlating {len(anonymous_features)} anonymous features with {len(public_features)} public features...\")\n",
    "\n",
    "    # Calculate the full correlation matrix for our subset of columns\n",
    "    corr_matrix = df_merged.select(anonymous_features + public_features).corr()\n",
    "\n",
    "    # *** START OF FIX ***\n",
    "    \n",
    "    # Manually add the feature names as a new column\n",
    "    # This is the column we will filter on.\n",
    "    corr_matrix_with_labels = corr_matrix.with_columns(\n",
    "        pl.Series(\"anonymous_feature\", all_features)\n",
    "    )\n",
    "\n",
    "    # Filter the matrix to only show (Anonymous Rows x Public Columns)\n",
    "    corr_subset = corr_matrix_with_labels.filter(\n",
    "        pl.col(\"anonymous_feature\").is_in(anonymous_features)\n",
    "    ).select(\n",
    "        [\"anonymous_feature\"] + public_features  # Use the new column name\n",
    "    )\n",
    "\n",
    "    # Melt the matrix to a long format for easy sorting\n",
    "    corr_long = corr_subset.melt(\n",
    "        id_vars=\"anonymous_feature\",  # Use the new column name\n",
    "        variable_name=\"public_feature\", \n",
    "        value_name=\"correlation\"\n",
    "    )\n",
    "    \n",
    "    # *** END OF FIX ***\n",
    "\n",
    "\n",
    "    # Sort by absolute correlation to find strongest links\n",
    "    corr_sorted = corr_long.with_columns(\n",
    "        pl.col(\"correlation\").abs().alias(\"abs_correlation\")\n",
    "    ).sort(\"abs_correlation\", descending=True)\n",
    "\n",
    "    print(\"\\n--- Top 30 Most Correlated Feature Pairs --- (Positive or Negative)\")\n",
    "    print(corr_sorted.head(30))\n",
    "\n",
    "    print(\"\\n--- Top 10 Positive Correlations ---\")\n",
    "    print(corr_sorted.sort(\"correlation\", descending=True).head(10))\n",
    "    \n",
    "    print(\"\\n--- Top 10 Negative Correlations ---\")\n",
    "    print(corr_sorted.sort(\"correlation\", descending=False).head(10))\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping correlation: Master dataframe was not created due to an error in a previous step.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
