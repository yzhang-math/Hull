{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a58aa266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# The training data path should be updated to your actual training file.\n",
    "TRAIN_DATA_PATH = \"./kaggle/train.csv\"\n",
    "SPY_DATA_PATH = \"./kaggle/spy-historical.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f8212c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_1(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"Generates 40 new features from the base data.\n",
    "      This function is the target of the evolutionary algorithm.\n",
    "    \n",
    "      Available Feature Categories:\n",
    "      - D* (Dummy/Binary features): 9 columns (D1-D9)\n",
    "      - E* (Macro Economic features): 20 columns (E1-E20)\n",
    "      - I* (Interest Rate features): 9 columns (I1-I9)\n",
    "      - M* (Market Dynamics/Technical features): 18 columns (M1-M18)\n",
    "      - P* (Price/Valuation features): 13 columns (P1-P13)\n",
    "      - S* (Sentiment features): 12 columns (S1-S12)\n",
    "      - V* (Volatility features): 13 columns (V1-V13)\n",
    "    \"\"\"\n",
    "    new_features = pl.DataFrame({\n",
    "        # --- New Interaction Features ---\n",
    "        'feat_M1_x_V10_x_P1': df['M1'] * df['V10'] * df['P1'],\n",
    "        'feat_P1_add_E10_div_I5': (df['P1'] + df['E10']) / (df['I5'] + 1e-6),\n",
    "        'feat_S3_div_I5_x_M12': df['S3'] / (df['I5'] + 1e-6) * df['M12'],\n",
    "        'feat_M12_x_V2_x_P2': df['M12'] * df['V2'] * df['P2'],\n",
    "        'feat_P2_sqrt_E4_x_S8': np.sqrt(df['P2'] * df['E4']) * df['S8'],\n",
    "        'feat_M2_x_S8_x_V2': df['M2'] * df['S8'] * df['V2'],\n",
    "        'feat_V10_cbrt_P5_x_E12': np.cbrt(df['V10'] * df['P5']) * df['E12'],\n",
    "        'feat_E12_x_I9_x_M1': df['E12'] * df['I9'] * df['M1'],\n",
    "        'feat_M1_log_V1_x_S7': np.log(df['M1'] + 1) * np.log(df['V1'] + 1) * df['S7'],\n",
    "        'feat_S7_abs_P1_x_I5': np.abs(df['S7'] - df['P1']) * df['I5'],\n",
    "    })\n",
    "    # Fill any nulls created by rolling windows\n",
    "    return new_features.with_columns(pl.all().forward_fill().backward_fill())\n",
    "\n",
    "\n",
    "\n",
    "def generate_features_2(df: pl.DataFrame) -> pl.DataFrame:\n",
    "  \"\"\"Generates 10 new features from the base data.\n",
    "    This function is the target of the evolutionary algorithm.\n",
    "  \n",
    "    Available Feature Categories:\n",
    "    - D* (Dummy/Binary features): 9 columns (D1-D9)\n",
    "    - E* (Macro Economic features): 20 columns (E1-E20)\n",
    "    - I* (Interest Rate features): 9 columns (I1-I9)\n",
    "    - M* (Market Dynamics/Technical features): 18 columns (M1-M18)\n",
    "    - P* (Price/Valuation features): 13 columns (P1-P13)\n",
    "    - S* (Sentiment features): 12 columns (S1-S12)\n",
    "    - V* (Volatility features): 13 columns (V1-V13)\n",
    "    - MOM* (Momentum features): 0 columns\n",
    "  \"\"\"\n",
    "  cols = ['M1', 'V1', 'P1', 'E1', 'S1', 'I1', 'M10', 'V10', 'P10', 'E10']\n",
    "  # Generate interaction features with exponential moving averages\n",
    "  new_features = pl.DataFrame({\n",
    "      #'feat_P1_add_E1': df[cols[2]] + df[cols[3]],\n",
    "      #'feat_S1_sub_I1': df[cols[4]] - df[cols[5]],\n",
    "      #'feat_M10_div_V10': (df[cols[6]] / (df[cols[7]] + 1e-6)),\n",
    "      #'feat_P10_x_E10': df[cols[8]] * df[cols[9]],\n",
    "      # Exponential moving averages instead of simple rolling means\n",
    "      'feat_V1_ema_5': df[cols[1]].rolling_mean(window_size=5, min_periods=1, center=True),\n",
    "      'feat_V1_ewm_std_5': df[cols[1]].rolling_std(window_size=5, min_periods=1, center=True),\n",
    "      'feat_M1_ema_20': df[cols[0]].rolling_mean(window_size=20, min_periods=1, center=True),\n",
    "      'feat_M1_ewm_std_20': df[cols[0]].rolling_std(window_size=20, min_periods=1, center=True),\n",
    "      # Relative strength index\n",
    "      'feat_RSI_14': (df[cols[2]].rolling_max(14) - df[cols[2]].rolling_min(14)) / (df[cols[2]].rolling_max(14) - df[cols[2]].rolling_min(14) + 1e-6),\n",
    "  })\n",
    "  return new_features.with_columns(pl.all().fill_null(0))\n",
    "\n",
    "def generate_features_3(df: pl.DataFrame) -> pl.DataFrame:\n",
    "  \"\"\"Generates 10 new features from the base data.\n",
    "    This function is the target of the evolutionary algorithm.\n",
    "  \n",
    "    Available Feature Categories:\n",
    "    - D* (Dummy/Binary features): 9 columns (D1-D9)\n",
    "    - E* (Macro Economic features): 20 columns (E1-E20)\n",
    "    - I* (Interest Rate features): 9 columns (I1-I9)\n",
    "    - M* (Market Dynamics/Technical features): 18 columns (M1-M18)\n",
    "    - P* (Price/Valuation features): 13 columns (P1-P13)\n",
    "    - S* (Sentiment features): 12 columns (S1-S12)\n",
    "    - V* (Volatility features): 13 columns (V1-V13)\n",
    "    - MOM* (Momentum features): 0 columns\n",
    "  \"\"\"\n",
    "  cols = ['M1', 'V1', 'P1', 'E1', 'S1', 'I1', 'M10', 'V10', 'P10', 'E10']\n",
    "  # Generate interaction features\n",
    "  new_features = pl.DataFrame({\n",
    "      # Pairwise interactions between different categories\n",
    "      'feat_M1_x_V1': df[cols[0]] * df[cols[1]],\n",
    "      'feat_P1_add_E1': df[cols[2]] + df[cols[3]],\n",
    "      'feat_S1_sub_I1': df[cols[4]] - df[cols[5]],\n",
    "      'feat_M10_div_V10': (df[cols[6]] / (df[cols[7]] + 1e-6)),\n",
    "      'feat_P10_x_E10': df[cols[8]] * df[cols[9]],\n",
    "      # Rolling window features on volatile columns\n",
    "      'feat_V1_roll_mean_5': df[cols[1]].rolling_mean(window_size=5),\n",
    "      'feat_V1_roll_std_5': df[cols[1]].rolling_std(window_size=5),\n",
    "      'feat_M1_roll_mean_20': df[cols[0]].rolling_mean(window_size=20),\n",
    "      'feat_M1_roll_std_20': df[cols[0]].rolling_std(window_size=20),\n",
    "      # A simple ratio\n",
    "      'feat_P1_div_M1': (df[cols[2]] / (df[cols[0]] + 1e-6)),\n",
    "      # New feature: Exponential moving average\n",
    "      'feat_M1_exp_mean_5': df[cols[0]].rolling_mean(window_size=5, min_periods=1, center=True),\n",
    "  })\n",
    "  # Fill any nulls created by rolling windows\n",
    "  return new_features.with_columns(pl.all().forward_fill().backward_fill())\n",
    "\n",
    "def generate_features_4(df: pl.DataFrame) -> pl.DataFrame:\n",
    "  \"\"\"Generates 40 new features from the base data.\n",
    "    This function is the target of the evolutionary algorithm.\n",
    "  \n",
    "    Available Feature Categories:\n",
    "    - D* (Dummy/Binary features): 9 columns (D1-D9)\n",
    "    - E* (Macro Economic features): 20 columns (E1-E20)\n",
    "    - I* (Interest Rate features): 9 columns (I1-I9)\n",
    "    - M* (Market Dynamics/Technical features): 18 columns (M1-M18)\n",
    "    - P* (Price/Valuation features): 13 columns (P1-P13)\n",
    "    - S* (Sentiment features): 12 columns (S1-S12)\n",
    "    - V* (Volatility features): 13 columns (V1-V13)\n",
    "  \"\"\"\n",
    "  \"\"\"Improved version of `generate_features_v0` with different features.\"\"\"\n",
    "  new_features = pl.DataFrame({\n",
    "      # --- 20 Pairwise Interactions ---\n",
    "      #'feat_M1_x_V2': df['M1'] * df['V2'],\n",
    "      #'feat_P1_add_E2': df['P1'] + df['E2'],\n",
    "      'feat_S1_sub_I2': df['S1'] - df['I2'],\n",
    "      'feat_M10_div_V11': df['M10'] / (df['V11'] + 1e-6),\n",
    "      'feat_P10_x_E11': df['P10'] * df['E11'],\n",
    "      'feat_M2_x_S4': df['M2'] * df['S4'],\n",
    "      'feat_V2_div_P3': df['V2'] / (df['P3'] + 1e-6),\n",
    "      'feat_E4_sub_I4': df['E4'] - df['I4'],\n",
    "      'feat_S7_add_M11': df['S7'] + df['M11'],\n",
    "      'feat_I5_x_V12': df['I5'] * df['V12'],\n",
    "      'feat_P5_div_S9': df['P5'] / (df['S9'] + 1e-6),\n",
    "      'feat_E12_x_I8': df['E12'] * df['I8'],\n",
    "      'feat_M1_div_S2': df['M1'] / (df['S2'] + 1e-6),\n",
    "      'feat_V1_add_P2': df['V1'] + df['P2'],\n",
    "      'feat_E1_sub_I2': df['E1'] - df['I2'],\n",
    "      'feat_M2_div_V3': df['M2'] / (df['V3'] + 1e-6),\n",
    "      'feat_P2_x_S4': df['P2'] * df['S4'],\n",
    "      'feat_E4_add_M11': df['E4'] + df['M11'],\n",
    "      'feat_I3_sub_V11': df['I3'] - df['V11'],\n",
    "      'feat_S7_x_P11': df['S7'] * df['P11'],\n",
    "      # --- 10 Rolling Window Features ---\n",
    "      'feat_V2_roll_mean_5': df['V2'].rolling_mean(window_size=5),\n",
    "      'feat_V2_roll_std_5': df['V2'].rolling_std(window_size=5),\n",
    "      'feat_M2_roll_mean_20': df['M2'].rolling_mean(window_size=20),\n",
    "      'feat_M2_roll_std_20': df['M2'].rolling_std(window_size=20),\n",
    "      'feat_P2_roll_max_10': df['P2'].rolling_max(window_size=10),\n",
    "      'feat_P2_roll_min_10': df['P2'].rolling_min(window_size=10),\n",
    "      'feat_E2_roll_mean_50': df['E2'].rolling_mean(window_size=50),\n",
    "      'feat_S2_roll_std_50': df['S2'].rolling_std(window_size=50),\n",
    "      'feat_I2_roll_mean_10': df['I2'].rolling_mean(window_size=10),\n",
    "      'feat_V11_roll_std_10': df['V11'].rolling_std(window_size=10),\n",
    "      # --- 10 Complex Interactions (3+ elements) ---\n",
    "      'feat_M1_V2_div_P2': (df['M1'] * df['V2']) / (df['P2'] + 1e-6),\n",
    "      'feat_E2_S2_add_I2': df['E2'] + df['S2'] - df['I2'],\n",
    "      'feat_M2_P3_sub_V3': df['M2'] + df['P3'] - df['V3'],\n",
    "      'feat_S8_div_E4_I4': df['S8'] / (df['E4'] + df['I4'] + 1e-6),\n",
    "      'feat_P6_x_M11_x_V11': df['P6'] * df['M11'] * df['V11'],\n",
    "      'feat_roll_diff_M2_5_20': df['M2'].rolling_mean(window_size=5) - df['M2'].rolling_mean(window_size=20),\n",
    "      'feat_roll_diff_V2_5_20': df['V2'].rolling_mean(window_size=5) - df['V2'].rolling_mean(window_size=20),\n",
    "      'feat_M_S_P_combo_v2': (df['M11'] - df['M2']) / (df['S2'] + df['P2'] + 1e-6),\n",
    "      'feat_V_E_I_combo_v2': (df['V12'] + df['V3']) * (df['E2'] - df['I2']),\n",
    "      'feat_ratio_of_ratios_v2': (df['M2']/(df['V2']+1e-6)) / (df['P2']/(df['S2']+1e-6)),\n",
    "  })\n",
    "  # Fill any nulls created by rolling windows\n",
    "  return new_features.with_columns(pl.all().forward_fill().backward_fill())\n",
    "\n",
    "def generate_features_5(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"Generates 40 new features from the base data.\n",
    "      This function is the target of the evolutionary algorithm.\n",
    "    \n",
    "      Available Feature Categories:\n",
    "      - D* (Dummy/Binary features): 9 columns (D1-D9)\n",
    "      - E* (Macro Economic features): 20 columns (E1-E20)\n",
    "      - I* (Interest Rate features): 9 columns (I1-I9)\n",
    "      - M* (Market Dynamics/Technical features): 18 columns (M1-M18)\n",
    "      - P* (Price/Valuation features): 13 columns (P1-P13)\n",
    "      - S* (Sentiment features): 12 columns (S1-S12)\n",
    "      - V* (Volatility features): 13 columns (V1-V13)\n",
    "    \"\"\"\n",
    "    \"\"\"Improved version of `generate_features_v2` with more complex interactions.\"\"\"\n",
    "    new_features = pl.DataFrame({\n",
    "        'feat_M1_add_V1': df['M1'] + df['V1'],\n",
    "        'feat_P1_sub_E1': df['P1'] - df['E1'],\n",
    "        'feat_S1_mul_I1': df['S1'] * df['I1'],\n",
    "        #'feat_M10_div_V10': df['M10'] / (df['V10'] + 1e-6),\n",
    "        'feat_P10_mul_E10': df['P10'] * df['E10'],\n",
    "        'feat_M2_mul_S3': df['M2'] * df['S3'],\n",
    "        'feat_V2_div_P2': df['V2'] / (df['P2'] + 1e-6),\n",
    "        'feat_E4_sub_I3': df['E4'] - df['I3'],\n",
    "        'feat_S7_add_M12': df['S7'] + df['M12'],\n",
    "        'feat_I5_mul_V11': df['I5'] * df['V11'],\n",
    "        # 'feat_V1_roll_mean_5': df['V1'].rolling_mean(window_size=5),\n",
    "        # 'feat_V1_roll_std_5': df['V1'].rolling_std(window_size=5),\n",
    "        # 'feat_M1_roll_mean_20': df['M1'].rolling_mean(window_size=20),\n",
    "        # 'feat_M1_roll_std_20': df['M1'].rolling_std(window_size=20),\n",
    "        'feat_P1_roll_max_10': df['P1'].rolling_max(window_size=10),\n",
    "        'feat_P1_roll_min_10': df['P1'].rolling_min(window_size=10),\n",
    "        'feat_E1_roll_mean_50': df['E1'].rolling_mean(window_size=50),\n",
    "        'feat_S1_roll_std_50': df['S1'].rolling_std(window_size=50),\n",
    "        'feat_I1_roll_mean_10': df['I1'].rolling_mean(window_size=10),\n",
    "        'feat_V10_roll_std_10': df['V10'].rolling_std(window_size=10),\n",
    "        'feat_M1_V1_div_P1': (df['M1'] * df['V1']) / (df['P1'] + 1e-6),\n",
    "        'feat_E1_S1_add_I1': df['E1'] + df['S1'] - df['I1'],\n",
    "        'feat_M2_P2_sub_V2': df['M2'] + df['P2'] - df['V2'],\n",
    "        'feat_S7_div_E4_I3': df['S7'] / (df['E4'] + df['I3'] + 1e-6),\n",
    "        'feat_P5_x_M10_x_V10': df['P5'] * df['M10'] * df['V10'],\n",
    "        'feat_roll_diff_M1_5_20': df['M1'].rolling_mean(window_size=5) - df['M1'].rolling_mean(window_size=20),\n",
    "        'feat_roll_diff_V1_5_20': df['V1'].rolling_mean(window_size=5) - df['V1'].rolling_mean(window_size=20),\n",
    "        'feat_M_S_P_combo': (df['M12'] - df['M1']) / (df['S1'] + df['P1'] + 1e-6),\n",
    "        'feat_V_E_I_combo': (df['V11'] + df['V2']) * (df['E1'] - df['I1']),\n",
    "        'feat_ratio_of_ratios': (df['M1']/(df['V1']+1e-6)) / (df['P1']/(df['S1']+1e-6)),\n",
    "        'feat_M1_roll_skew_5': df['M1'].rolling_skew(window_size=5),\n",
    "        'feat_V1_roll_kurt_5': df['V1'].rolling_kurtosis(window_size=5),\n",
    "        'feat_E1_roll_skew_20': df['E1'].rolling_skew(window_size=20),\n",
    "        'feat_S1_roll_kurt_20': df['S1'].rolling_kurtosis(window_size=20),\n",
    "        'feat_I1_roll_skew_10': df['I1'].rolling_skew(window_size=10),\n",
    "        'feat_P1_roll_kurt_10': df['P1'].rolling_kurtosis(window_size=10),\n",
    "        'feat_M1_V1_E1_S1': df['M1'] * df['V1'] * df['E1'] * df['S1'],\n",
    "        'feat_P1_S1_I1_V1': df['P1'] * df['S1'] * df['I1'] * df['V1'],\n",
    "        'feat_M10_V10_P10_E10': df['M10'] * df['V10'] * df['P10'] * df['E10'],\n",
    "        'feat_E1_S1_V1_I1': df['E1'] * df['S1'] * df['V1'] * df['I1'],\n",
    "        'feat_complex_interaction': df['M1'] * (df['V1'] - df['E1']) / (df['P1'] + df['I1'] + 1e-6),\n",
    "    })\n",
    "    # Fill any nulls created by rolling windows\n",
    "    return new_features.with_columns(pl.all().forward_fill().backward_fill())\n",
    "\n",
    "\n",
    "def generate_features_6 (df: pl.DataFrame) -> pl.DataFrame:\n",
    "  \"\"\"Generates 40 new features from the base data.\n",
    "    This function is the target of the evolutionary algorithm.\n",
    "  \n",
    "    Available Feature Categories:\n",
    "    - D* (Dummy/Binary features): 9 columns (D1-D9)\n",
    "    - E* (Macro Economic features): 20 columns (E1-E20)\n",
    "    - I* (Interest Rate features): 9 columns (I1-I9)\n",
    "    - M* (Market Dynamics/Technical features): 18 columns (M1-M18)\n",
    "    - P* (Price/Valuation features): 13 columns (P1-P13)\n",
    "    - S* (Sentiment features): 12 columns (S1-S12)\n",
    "    - V* (Volatility features): 13 columns (V1-V13)\n",
    "  \"\"\"\n",
    "  new_features = pl.DataFrame({\n",
    "      # --- 10 New Pairwise Interactions ---\n",
    "      'feat_M1_x_V2': df['M1'] * df['V2'],\n",
    "      'feat_P1_add_E2': df['P1'] + df['E2'],\n",
    "      'feat_S2_sub_I2': df['S2'] - df['I2'],\n",
    "      'feat_M3_div_V3': df['M3'] / (df['V3'] + 1e-6),\n",
    "      'feat_P2_x_E3': df['P2'] * df['E3'],\n",
    "      'feat_M4_x_S4': df['M4'] * df['S4'],\n",
    "      'feat_V4_div_P5': df['V4'] / (df['P5'] + 1e-6),\n",
    "      'feat_E5_sub_I4': df['E5'] - df['I4'],\n",
    "      'feat_S8_add_M13': df['S8'] + df['M13'],\n",
    "      'feat_I7_x_V12': df['I7'] * df['V12'],\n",
    "  })\n",
    "  return new_features.with_columns(pl.all().fill_null(0))\n",
    "\n",
    "def generate_features_7 (df: pl.DataFrame) -> pl.DataFrame:\n",
    "  \"\"\"Generates new features from the base data.\n",
    "    This function is the target of the evolutionary algorithm.\n",
    "  \n",
    "    Available Feature Categories:\n",
    "    - D* (Dummy/Binary features): 9 columns (D1-D9)\n",
    "    - E* (Macro Economic features): 20 columns (E1-E20)\n",
    "    - I* (Interest Rate features): 9 columns (I1-I9)\n",
    "    - M* (Market Dynamics/Technical features): 18 columns (M1-M18)\n",
    "    - P* (Price/Valuation features): 13 columns (P1-P13)\n",
    "    - S* (Sentiment features): 12 columns (S1-S12)\n",
    "    - V* (Volatility features): 13 columns (V1-V13)\n",
    "  \"\"\"\n",
    "  new_features = pl.DataFrame({\n",
    "      # --- 20 Pairwise Interactions ---\n",
    "      'feat_M1_x_V1': df['M1'] * df['V1'],\n",
    "      'feat_P1_add_E1': df['P1'] + df['E1'],\n",
    "      'feat_S1_sub_I1': df['S1'] - df['I1'],\n",
    "      'feat_M10_div_V10': df['M10'] / (df['V10'] + 1e-6),\n",
    "      'feat_P10_x_E10': df['P10'] * df['E10'],\n",
    "      'feat_M2_x_S3': df['M2'] * df['S3'],\n",
    "      'feat_V2_div_P2': df['V2'] / (df['P2'] + 1e-6),\n",
    "      'feat_E4_sub_I3': df['E4'] - df['I3'],\n",
    "      'feat_S7_add_M12': df['S7'] + df['M12'],\n",
    "      'feat_I5_x_V11': df['I5'] * df['V11'],\n",
    "      'feat_P5_div_S8': df['P5'] / (df['S8'] + 1e-6),\n",
    "      'feat_E12_x_I9': df['E12'] * df['I9'],\n",
    "      'feat_M1_div_S1': df['M1'] / (df['S1'] + 1e-6),\n",
    "      'feat_V1_add_P1': df['V1'] + df['P1'],\n",
    "      'feat_E1_sub_I1': df['E1'] - df['I1'],\n",
    "      'feat_M2_div_V2': df['M2'] / (df['V2'] + 1e-6),\n",
    "      'feat_P2_x_S3': df['P2'] * df['S3'],\n",
    "      'feat_E4_add_M10': df['E4'] + df['M10'],\n",
    "      'feat_I3_sub_V10': df['I3'] - df['V10'],\n",
    "      'feat_S7_x_P10': df['S7'] * df['P10'],\n",
    "      # --- 10 Rolling Window Features ---\n",
    "      'feat_V2_roll_mean_5': df['V2'].rolling_mean(window_size=5),\n",
    "      'feat_V1_roll_std_5': df['V1'].rolling_std(window_size=5),\n",
    "      'feat_M1_roll_mean_20': df['M1'].rolling_mean(window_size=20),\n",
    "      'feat_M3_roll_std_20': df['M3'].rolling_std(window_size=20),\n",
    "      'feat_P1_roll_max_10': df['P1'].rolling_max(window_size=10),\n",
    "      'feat_P1_roll_min_10': df['P1'].rolling_min(window_size=10),\n",
    "      'feat_E5_roll_mean_50': df['E5'].rolling_mean(window_size=50),\n",
    "      'feat_S1_roll_std_50': df['S1'].rolling_std(window_size=50),\n",
    "      'feat_I1_roll_mean_10': df['I1'].rolling_mean(window_size=10),\n",
    "      'feat_V10_roll_std_10': df['V10'].rolling_std(window_size=10),\n",
    "      # --- 10 Complex Interactions (3+ elements) ---\n",
    "      'feat_M1_V1_div_P1': (df['M1'] * df['V1']) / (df['P1'] + 1e-6),\n",
    "      'feat_E1_S1_add_I1': df['E1'] + df['S1'] - df['I1'],\n",
    "      'feat_M2_P2_sub_V2': df['M2'] + df['P2'] - df['V2'],\n",
    "      'feat_S7_div_E4_I3': df['S7'] / (df['E4'] + df['I3'] + 1e-6),\n",
    "      'feat_P5_x_M10_x_V10': df['P5'] * df['M10'] * df['V10'],\n",
    "      'feat_roll_diff_M1_5_20': df['M1'].rolling_mean(window_size=5) - df['M1'].rolling_mean(window_size=20),\n",
    "      'feat_roll_diff_V1_5_20': df['V1'].rolling_mean(window_size=5) - df['V1'].rolling_mean(window_size=20),\n",
    "      'feat_M_S_P_combo': (df['M12'] - df['M1']) / (df['S1'] + df['P1'] + 1e-6),\n",
    "      'feat_V_E_I_combo': (df['V11'] + df['V2']) * (df['E1'] - df['I1']),\n",
    "      'feat_ratio_of_ratios': (df['M1']/(df['V1']+1e-6)) / (df['P1']/(df['S1']+1e-6)),\n",
    "      # --- 10 New Features ---\n",
    "      'feat_M1_x_V1_x_P1': df['M1'] * df['V1'] * df['P1'],\n",
    "      'feat_E1_div_S1': df['E1'] / (df['S1'] + 1e-6),\n",
    "      'feat_I1_sub_V1': df['I1'] - df['V1'],\n",
    "      'feat_M10_add_V10': df['M10'] + df['V10'],\n",
    "      'feat_P10_div_E10': df['P10'] / (df['E10'] + 1e-6),\n",
    "      'feat_M2_add_S3': df['M2'] + df['S3'],\n",
    "      'feat_V2_x_P2': df['V2'] * df['P2'],\n",
    "      'feat_E4_add_I3': df['E4'] + df['I3'],\n",
    "      'feat_S7_div_M12': df['S7'] / (df['M12'] + 1e-6),\n",
    "      'feat_I5_div_V11': df['I5'] / (df['V11'] + 1e-6),\n",
    "      'feat_M1_log_P1': np.log(df['M1'] + 1e-6) / np.log(df['P1'] + 1e-6),\n",
    "  })\n",
    "  # Fill any nulls created by rolling windows\n",
    "  return new_features.with_columns(pl.all().forward_fill())\n",
    "  return new_features.with_columns(pl.all().forward_fill().backward_fill())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3cac177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6990, 98)\n",
      "\n",
      "--- Joining weekday feature onto sliced data ---\n",
      "Initial DataFrame shape: (6990, 99)\n",
      "Base DataFrame shape before cleaning: (6990, 99)\n",
      "Base DataFrame shape during cleaning: (6990, 98)\n",
      "Base DataFrame shape after cleaning: (6990, 98)\n",
      "Processed DataFrame shape: (6990, 149)\n",
      "Strategy Volatility: 19.45%, Market Volatility: 19.44%, Sharpe: 1.3630, Adjusted Sharpe: 1.3630\n",
      "Strategy Volatility: 35.29%, Market Volatility: 20.40%, Sharpe: -0.3061, Adjusted Sharpe: -0.1350\n",
      "Strategy Volatility: 34.80%, Market Volatility: 23.32%, Sharpe: -0.7309, Adjusted Sharpe: -0.5657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25427/131279597.py:17: DeprecationWarning: the argument `min_periods` for `Expr.rolling_mean` is deprecated. It was renamed to `min_samples` in version 1.21.0.\n",
      "  pl.selectors.numeric().rolling_mean(window_size=5, min_periods=1)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/polars/series/series.py:1571: RuntimeWarning: invalid value encountered in log\n",
      "  lambda out: ufunc(*args, out=out, dtype=dtype_char, **kwargs),\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy Volatility: 30.12%, Market Volatility: 22.91%, Sharpe: -0.4288, Adjusted Sharpe: -0.3845\n",
      "Strategy Volatility: 20.44%, Market Volatility: 21.65%, Sharpe: -0.7497, Adjusted Sharpe: -0.0773\n",
      "Strategy Volatility: 11.43%, Market Volatility: 11.69%, Sharpe: 2.1750, Adjusted Sharpe: 2.1750\n",
      "Strategy Volatility: 11.60%, Market Volatility: 10.17%, Sharpe: 1.3299, Adjusted Sharpe: 1.3299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy Volatility: 13.60%, Market Volatility: 10.90%, Sharpe: -0.0071, Adjusted Sharpe: -0.0068\n",
      "Strategy Volatility: 10.70%, Market Volatility: 9.96%, Sharpe: 2.1841, Adjusted Sharpe: 2.1841\n",
      "Strategy Volatility: 31.55%, Market Volatility: 19.67%, Sharpe: -0.4006, Adjusted Sharpe: -0.2853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy Volatility: 45.74%, Market Volatility: 34.60%, Sharpe: 0.2060, Adjusted Sharpe: 0.1836\n",
      "Strategy Volatility: 23.34%, Market Volatility: 17.09%, Sharpe: 1.0957, Adjusted Sharpe: 0.9403\n",
      "Strategy Volatility: 22.04%, Market Volatility: 16.29%, Sharpe: 0.8843, Adjusted Sharpe: 0.7578\n",
      "Strategy Volatility: 32.15%, Market Volatility: 21.95%, Sharpe: 0.0437, Adjusted Sharpe: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy Volatility: 14.33%, Market Volatility: 12.77%, Sharpe: 0.8061, Adjusted Sharpe: 0.7426\n",
      "Strategy Volatility: 11.71%, Market Volatility: 11.51%, Sharpe: 1.3440, Adjusted Sharpe: 1.2002\n",
      "Strategy Volatility: 12.81%, Market Volatility: 11.50%, Sharpe: 1.1076, Adjusted Sharpe: 1.0801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy Volatility: 26.62%, Market Volatility: 16.45%, Sharpe: -0.3171, Adjusted Sharpe: -0.2236\n",
      "Strategy Volatility: 11.49%, Market Volatility: 11.13%, Sharpe: 2.2836, Adjusted Sharpe: 2.2836\n",
      "Strategy Volatility: 7.30%, Market Volatility: 6.77%, Sharpe: 3.1199, Adjusted Sharpe: 3.1199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy Volatility: 29.13%, Market Volatility: 16.90%, Sharpe: -0.8030, Adjusted Sharpe: -0.2282\n",
      "Strategy Volatility: 16.23%, Market Volatility: 12.76%, Sharpe: 2.2992, Adjusted Sharpe: 2.1455\n",
      "Strategy Volatility: 40.22%, Market Volatility: 25.72%, Sharpe: 0.8723, Adjusted Sharpe: 0.6396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy Volatility: 17.50%, Market Volatility: 12.12%, Sharpe: 2.7953, Adjusted Sharpe: 2.2470\n",
      "Strategy Volatility: 41.90%, Market Volatility: 23.28%, Sharpe: -0.8573, Adjusted Sharpe: -0.1735\n",
      "Strategy Volatility: 15.66%, Market Volatility: 15.32%, Sharpe: 0.7199, Adjusted Sharpe: 0.7199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:46] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:46] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:46] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:46] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:46] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:46] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy Volatility: 12.90%, Market Volatility: 12.52%, Sharpe: 1.8093, Adjusted Sharpe: 1.7799\n",
      "Strategy Volatility: 25.07%, Market Volatility: 16.19%, Sharpe: 0.1947, Adjusted Sharpe: 0.1234\n",
      "\n",
      "Mean CV Score: 0.8200, std: 1.0065\n",
      "Strategy Volatility: 24.70%, Market Volatility: 17.65%, Sharpe: 0.3647, Adjusted Sharpe: 0.3042\n",
      " Overall Score Calculation: 0.3042\n",
      "Final Evaluation Score: 0.3042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:46] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [23:24:46] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1744329155408/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate(excessarg: int) -> float:\n",
    "    \"\"\"\n",
    "    Main evaluation function for FunSearch. It loads the data\n",
    "    and runs the solver which performs cross-validation.\n",
    "    \"\"\"\n",
    "    full_train_df = pl.read_csv(TRAIN_DATA_PATH)\n",
    "    # Use a slice of data for faster evaluation runs during development\n",
    "    df_raw = full_train_df.slice(2000)\n",
    "    print(df_raw.shape)\n",
    "\n",
    "    #fill nulls in df with mean\n",
    "    df = df_raw.with_columns(\n",
    "        # Select all numeric columns for the operation\n",
    "        pl.selectors.numeric()\n",
    "          # Step 1: Attempt to fill with the rolling mean of each respective column\n",
    "          .fill_null(\n",
    "              pl.selectors.numeric().rolling_mean(window_size=5, min_periods=1)\n",
    "          )\n",
    "          # Step 2: Fall back to the global column mean for any remaining nulls\n",
    "          #.fill_null(strategy='mean')\n",
    "    )\n",
    "    df = df.with_columns(\n",
    "    pl.col(\"date_id\").cast(pl.Int64)\n",
    "    )\n",
    "    \n",
    "    weekday_df = add_weekday_column(SPY_DATA_PATH)\n",
    "    print(\"\\n--- Joining weekday feature onto sliced data ---\")\n",
    "    # Join the weekday information onto the sliced training data.\n",
    "    # A 'left' join ensures we keep all rows from the original `df`.\n",
    "    df_with_features = df.join(weekday_df, on=\"date_id\", how=\"left\")\n",
    "    # print(\"DataFrame after join:\")\n",
    "    # print(df_with_features.shape)\n",
    "    return solve(df_with_features)\n",
    "  \n",
    "def add_weekday_column(input_csv_path: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a CSV file, adds a 'weekday' column based on the 'Date' column,\n",
    "    and saves the result to a new CSV file.\n",
    "\n",
    "    Args:\n",
    "        input_csv_path (str): The path to the source CSV file.\n",
    "        output_csv_path (str): The path where the output CSV will be saved.\n",
    "    \"\"\"\n",
    "    # Read the CSV file into a Polars DataFrame\n",
    "    df = pl.read_csv(input_csv_path)\n",
    "\n",
    "    # Add a new column named 'weekday'\n",
    "    # 1. Select the 'Date' column.\n",
    "    # 2. Convert the string representation to a proper date type.\n",
    "    # 3. Use the .dt.weekday() function to get the day of the week (Monday=1, Sunday=7).\n",
    "    # 4. Alias the new expression to 'weekday'.\n",
    "    df_with_weekday = df.with_columns(\n",
    "        pl.col(\"Date\").str.to_date().dt.weekday().alias(\"weekday\")\n",
    "    )\n",
    "\n",
    "    # Print the transformed DataFrame to the console to show the result\n",
    "    returned_df = df_with_weekday.select([\"date_id\", \"weekday\"])\n",
    "    return returned_df\n",
    "\n",
    "# def solve(df: pl.DataFrame) -> float:\n",
    "#     \"\"\"\n",
    "#     A placeholder for the user's actual solving/modeling function.\n",
    "#     This dummy function just prints the DataFrame it receives to show\n",
    "#     that the join operation was successful.\n",
    "#     \"\"\"\n",
    "#     print(\"--- DataFrame passed to solve() ---\")\n",
    "#     print(df.shape)\n",
    "#     # In a real scenario, this would return a score based on a model's performance\n",
    "#     # If the dataframe passed here is empty, a CV function would fail.\n",
    "#     if df.height == 0:\n",
    "#         raise ValueError(\"DataFrame passed to solve() is empty.\")\n",
    "#     return 1.0\n",
    "\n",
    "def solve(df: pl.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Runs a full time-series cross-validation process to evaluate\n",
    "    the features generated by the `generate_features` function.\n",
    "    This version pre-generates features to avoid a CPU bottleneck.\n",
    "    \"\"\"\n",
    "    # --- Helper functions (unchanged) ---\n",
    "    def calculate_competition_score(y_true_df: pl.DataFrame, y_pred_signals: np.ndarray) -> float:\n",
    "        ''' Calculates the competition score based on true values and predicted signals. '''\n",
    "        solution = y_true_df.to_pandas()\n",
    "        solution['position'] = y_pred_signals\n",
    "        solution['strategy_returns'] = (\n",
    "            solution['risk_free_rate'] * (1 - solution['position']) +\n",
    "            solution['position'] * solution['forward_returns']\n",
    "        )\n",
    "        strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate']\n",
    "        strategy_geo_mean = (1 + strategy_excess_returns).prod() ** (1 / len(solution)) - 1\n",
    "        strategy_std = solution['strategy_returns'].std()\n",
    "        if strategy_std == 0: return 0.0\n",
    "        trading_days_per_yr = 252\n",
    "        sharpe = strategy_geo_mean / strategy_std * np.sqrt(trading_days_per_yr)\n",
    "        market_std = solution['forward_returns'].std()\n",
    "        market_volatility = market_std * np.sqrt(trading_days_per_yr) * 100\n",
    "        strategy_volatility = strategy_std * np.sqrt(trading_days_per_yr) * 100\n",
    "        excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n",
    "        vol_penalty = 1 + excess_vol\n",
    "        market_excess_returns = solution['forward_returns'] - solution['risk_free_rate']\n",
    "        market_geo_mean = (1 + market_excess_returns).prod() ** (1 / len(solution)) - 1\n",
    "        return_gap = max(0, (market_geo_mean - strategy_geo_mean) * 100 * trading_days_per_yr)\n",
    "        return_penalty = 1 + (return_gap**2) / 100\n",
    "        adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n",
    "        print(f\"Strategy Volatility: {strategy_volatility:.2f}%, Market Volatility: {market_volatility:.2f}%, Sharpe: {sharpe:.4f}, Adjusted Sharpe: {adjusted_sharpe:.4f}\")\n",
    "        return adjusted_sharpe\n",
    "\n",
    "    def convert_to_signal(predictions: np.ndarray, multiplier: float = 400.0) -> np.ndarray:\n",
    "        ''' Converts raw model predictions into trading signals in the range [0, 2]. '''\n",
    "        signals = predictions * multiplier + 1\n",
    "        return np.clip(signals, 0.0, 2.0)\n",
    "\n",
    "    # --- Feature Generation and Data Prep (Moved Outside the Loop) ---\n",
    "    #print(\"Preparing data and generating features once...\")\n",
    "    print(f\"Initial DataFrame shape: {df.shape}\")\n",
    "    # 1. Prepare base data\n",
    "    base_df = df.rename({'market_forward_excess_returns': 'target'})\n",
    "    feature_cols = [col for col in base_df.columns if col != 'date_id']\n",
    "    print(f\"Base DataFrame shape before cleaning: {base_df.shape}\")\n",
    "    base_df = base_df.with_columns(pl.col(feature_cols).cast(pl.Float64, strict=False))\n",
    "    #base_df.write_csv(\"debug_base_df_before_cleaning.csv\")\n",
    "    base_df = base_df.drop('E7')\n",
    "    print(f\"Base DataFrame shape during cleaning: {base_df.shape}\")\n",
    "    \n",
    "    df = df.with_columns(\n",
    "    pl.col(\"date_id\").cast(pl.Int64)\n",
    "    )\n",
    "    base_df = base_df.with_columns(pl.all().forward_fill())\n",
    "    #base_df = base_df.with_columns(pl.all().forward_fill()).drop_nulls()\n",
    "    print(f\"Base DataFrame shape after cleaning: {base_df.shape}\")\n",
    "\n",
    "\n",
    "    # 2. Generate new features using the evolved function\n",
    "    # new_features_df_1 = generate_features_1(base_df)\n",
    "    # new_features_df_2 = generate_features_2(base_df)\n",
    "    # new_features_df_3 = generate_features_3(base_df)\n",
    "    # new_features_df_4 = generate_features_4(base_df)\n",
    "    # new_features_df_5 = generate_features_5(base_df)\n",
    "    # new_features_df_6 = generate_features_6(base_df)\n",
    "    # newf = [new_features_df_1, new_features_df_2, new_features_df_3, new_features_df_4,new_features_df_5, new_features_df_6]\n",
    "    #newf = [new_features_df_1, new_features_df_2, new_features_df_6]\n",
    "    #newf = [new_features_df_1, new_features_df_5]\n",
    "    #new_features_df = pl.concat(newf, how=\"horizontal\")\n",
    "    new_features_df = generate_features_7(base_df)\n",
    "\n",
    "    # 3. Combine base data with new features\n",
    "    processed_df = pl.concat([base_df, new_features_df], how=\"horizontal\")\n",
    "    #processed_df = base_df\n",
    "\n",
    "    print(f\"Processed DataFrame shape: {processed_df.shape}\")\n",
    "\n",
    "    # 4. Set up data for modeling\n",
    "    base_features = [col for col in base_df.columns if col not in [\"date_id\", \"forward_returns\", \"risk_free_rate\", \"target\"]]\n",
    "    new_feature_names = new_features_df.columns\n",
    "    ALL_FEATURES = base_features #+ new_feature_names\n",
    "    #ALL_FEATURES = ['']\n",
    "    TARGET_COL = \"target\"\n",
    "\n",
    "    X = processed_df.select(ALL_FEATURES)\n",
    "    y = processed_df.select(TARGET_COL)\n",
    "    scorer_info_df = processed_df.select([\"forward_returns\", \"risk_free_rate\"])\n",
    "\n",
    "    # --- Time-Series Cross-Validation (Loop is now much lighter) ---\n",
    "    # print(\"Starting cross-validation loop...\")\n",
    "    nsplits = 28\n",
    "    tscv = TimeSeriesSplit(n_splits=nsplits)\n",
    "    cv_scores = []\n",
    "    entire_signal = []\n",
    "    entire_ytest = scorer_info_df.clear()\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "        #print(f\"  Starting Fold {i+1}/{nsplits}...\")\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_test_info = scorer_info_df[test_index]\n",
    "\n",
    "        model = xgb.XGBRegressor(\n",
    "            objective='reg:absoluteerror', n_estimators=50, device='cuda',\n",
    "            learning_rate=0.05, max_depth=5, subsample=0.8, colsample_bytree=0.8,\n",
    "            n_jobs=-1, random_state=42\n",
    "        )\n",
    "        \n",
    "        # GPU is now the primary worker here\n",
    "        model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "        predictions = model.predict(X_test)\n",
    "        signals = convert_to_signal(predictions)\n",
    "        score = calculate_competition_score(y_test_info, signals)\n",
    "        cv_scores.append(score)\n",
    "        entire_signal.extend(signals)\n",
    "        entire_ytest.extend(y_test_info)\n",
    "        #print(f\"  Fold {i+1}/{nsplits} Score: {score:.4f}\")\n",
    "\n",
    "    mean_score = np.mean(cv_scores)\n",
    "    print(f\"\\nMean CV Score: {mean_score:.4f}, std: {np.std(cv_scores):.4f}\")\n",
    "    overall_score = calculate_competition_score(entire_ytest, entire_signal)\n",
    "    print(f\" Overall Score Calculation: {overall_score:.4f}\")\n",
    "    return overall_score\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example call to evaluate function\n",
    "    final_score = evaluate(0)\n",
    "    print(f\"Final Evaluation Score: {final_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66af5650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6990, 98)\n",
      "\n",
      "--- Joining weekday feature onto sliced data ---\n",
      "Strategy Volatility: 28.62%, Market Volatility: 15.94%, Sharpe: -0.0878, Adjusted Sharpe: -0.0479\n",
      "Strategy Volatility: 21.21%, Market Volatility: 12.73%, Sharpe: 1.0726, Adjusted Sharpe: 0.7316\n",
      "Strategy Volatility: 51.03%, Market Volatility: 26.93%, Sharpe: 0.7052, Adjusted Sharpe: 0.4160\n",
      "Strategy Volatility: 20.83%, Market Volatility: 16.07%, Sharpe: 2.2220, Adjusted Sharpe: 2.0275\n",
      "Strategy Volatility: 20.37%, Market Volatility: 12.49%, Sharpe: 1.1389, Adjusted Sharpe: 0.7959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/polars/series/series.py:1571: RuntimeWarning: invalid value encountered in sqrt\n",
      "  lambda out: ufunc(*args, out=out, dtype=dtype_char, **kwargs),\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/polars/series/series.py:1571: RuntimeWarning: invalid value encountered in log\n",
      "  lambda out: ufunc(*args, out=out, dtype=dtype_char, **kwargs),\n",
      "/tmp/ipykernel_14973/700726612.py:54: DeprecationWarning: the argument `min_periods` for `Expr.rolling_mean` is deprecated. It was renamed to `min_samples` in version 1.21.0.\n",
      "  'feat_V1_ema_5': df[cols[1]].rolling_mean(window_size=5, min_periods=1, center=True),\n",
      "/tmp/ipykernel_14973/700726612.py:55: DeprecationWarning: the argument `min_periods` for `Expr.rolling_std` is deprecated. It was renamed to `min_samples` in version 1.21.0.\n",
      "  'feat_V1_ewm_std_5': df[cols[1]].rolling_std(window_size=5, min_periods=1, center=True),\n",
      "/tmp/ipykernel_14973/700726612.py:56: DeprecationWarning: the argument `min_periods` for `Expr.rolling_mean` is deprecated. It was renamed to `min_samples` in version 1.21.0.\n",
      "  'feat_M1_ema_20': df[cols[0]].rolling_mean(window_size=20, min_periods=1, center=True),\n",
      "/tmp/ipykernel_14973/700726612.py:57: DeprecationWarning: the argument `min_periods` for `Expr.rolling_std` is deprecated. It was renamed to `min_samples` in version 1.21.0.\n",
      "  'feat_M1_ewm_std_20': df[cols[0]].rolling_std(window_size=20, min_periods=1, center=True),\n",
      "/tmp/ipykernel_14973/700726612.py:94: DeprecationWarning: the argument `min_periods` for `Expr.rolling_mean` is deprecated. It was renamed to `min_samples` in version 1.21.0.\n",
      "  'feat_M1_exp_mean_5': df[cols[0]].rolling_mean(window_size=5, min_periods=1, center=True),\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy Volatility: 44.18%, Market Volatility: 24.63%, Sharpe: -1.2821, Adjusted Sharpe: -0.1086\n",
      "Strategy Volatility: 16.30%, Market Volatility: 17.38%, Sharpe: 0.6788, Adjusted Sharpe: 0.2637\n",
      "Strategy Volatility: 11.09%, Market Volatility: 11.43%, Sharpe: 2.3504, Adjusted Sharpe: 2.3504\n",
      "Strategy Volatility: 18.35%, Market Volatility: 12.54%, Sharpe: 1.5822, Adjusted Sharpe: 1.2518\n",
      "Strategy Volatility: 31.36%, Market Volatility: 17.63%, Sharpe: 0.0348, Adjusted Sharpe: 0.0188\n",
      "\n",
      "Mean CV Score: 0.7699, std: 0.8185\n",
      "Final Evaluation Score: 0.7699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/envs/ml_311/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "def solve(df: pl.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Runs a full time-series cross-validation process to evaluate\n",
    "    the features generated by the `generate_features` function.\n",
    "    This version uses a LightGBM model.\n",
    "    \"\"\"\n",
    "    # --- Helper functions (unchanged) ---\n",
    "    def calculate_competition_score(y_true_df: pl.DataFrame, y_pred_signals: np.ndarray) -> float:\n",
    "        ''' Calculates the competition score based on true values and predicted signals. '''\n",
    "        solution = y_true_df.to_pandas()\n",
    "        solution['position'] = y_pred_signals\n",
    "        solution['strategy_returns'] = (\n",
    "            solution['risk_free_rate'] * (1 - solution['position']) +\n",
    "            solution['position'] * solution['forward_returns']\n",
    "        )\n",
    "        strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate']\n",
    "        strategy_geo_mean = (1 + strategy_excess_returns).prod() ** (1 / len(solution)) - 1\n",
    "        strategy_std = solution['strategy_returns'].std()\n",
    "        if strategy_std == 0: return 0.0\n",
    "        trading_days_per_yr = 252\n",
    "        sharpe = strategy_geo_mean / strategy_std * np.sqrt(trading_days_per_yr)\n",
    "        market_std = solution['forward_returns'].std()\n",
    "        market_volatility = market_std * np.sqrt(trading_days_per_yr) * 100\n",
    "        strategy_volatility = strategy_std * np.sqrt(trading_days_per_yr) * 100\n",
    "        excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n",
    "        vol_penalty = 1 + excess_vol\n",
    "        market_excess_returns = solution['forward_returns'] - solution['risk_free_rate']\n",
    "        market_geo_mean = (1 + market_excess_returns).prod() ** (1 / len(solution)) - 1\n",
    "        return_gap = max(0, (market_geo_mean - strategy_geo_mean) * 100 * trading_days_per_yr)\n",
    "        return_penalty = 1 + (return_gap**2) / 100\n",
    "        adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n",
    "        print(f\"Strategy Volatility: {strategy_volatility:.2f}%, Market Volatility: {market_volatility:.2f}%, Sharpe: {sharpe:.4f}, Adjusted Sharpe: {adjusted_sharpe:.4f}\")\n",
    "        return adjusted_sharpe\n",
    "\n",
    "    def convert_to_signal(predictions: np.ndarray, multiplier: float = 400.0) -> np.ndarray:\n",
    "        ''' Converts raw model predictions into trading signals in the range [0, 2]. '''\n",
    "        signals = predictions * multiplier + 1\n",
    "        return np.clip(signals, 0.0, 2.0)\n",
    "\n",
    "    # --- Feature Generation and Data Prep ---\n",
    "    base_df = df.rename({'market_forward_excess_returns': 'target'})\n",
    "    feature_cols = [col for col in base_df.columns if col != 'date_id']\n",
    "    base_df = base_df.with_columns(pl.col(feature_cols).cast(pl.Float64, strict=False))\n",
    "    base_df = base_df.with_columns(pl.all().forward_fill()).drop_nulls()\n",
    "\n",
    "    # Generate and combine features\n",
    "    new_features_df_1 = generate_features_1(base_df)\n",
    "    new_features_df_2 = generate_features_2(base_df)\n",
    "    new_features_df_3 = generate_features_3(base_df)\n",
    "    new_features_df_4 = generate_features_4(base_df)\n",
    "    new_features_df_5 = generate_features_5(base_df)\n",
    "    new_features_df_6 = generate_features_6(base_df)\n",
    "    #newf = [new_features_df_1, new_features_df_2, new_features_df_3, new_features_df_4, new_features_df_5, new_features_df_6]\n",
    "    newf = [new_features_df_1, new_features_df_2, new_features_df_3, new_features_df_5, new_features_df_6]\n",
    "    new_features_df = pl.concat(newf, how=\"horizontal\")\n",
    "    new_features_df = generate_features_7(base_df)\n",
    "    \n",
    "    processed_df = pl.concat([base_df, new_features_df], how=\"horizontal\")\n",
    "\n",
    "    # Setup data for modeling\n",
    "    base_features = [col for col in base_df.columns if col not in [\"date_id\", \"forward_returns\", \"risk_free_rate\", \"target\"]]\n",
    "    new_feature_names = new_features_df.columns\n",
    "    ALL_FEATURES = base_features + new_feature_names\n",
    "    TARGET_COL = \"target\"\n",
    "\n",
    "    X = processed_df.select(ALL_FEATURES)\n",
    "    y = processed_df.select(TARGET_COL)\n",
    "    scorer_info_df = processed_df.select([\"forward_returns\", \"risk_free_rate\"])\n",
    "\n",
    "    # --- Time-Series Cross-Validation ---\n",
    "    nsplits = 10\n",
    "    tscv = TimeSeriesSplit(n_splits=nsplits)\n",
    "    cv_scores = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_test_info = scorer_info_df[test_index]\n",
    "\n",
    "        # Define the LightGBM model\n",
    "        model = lgb.LGBMRegressor(\n",
    "            objective='regression_l1',  # MAE, an alternative to squared error\n",
    "            n_estimators=100,\n",
    "            device='cpu',              # Use 'cpu' if you don't have a compatible GPU\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            subsample=0.8,             # Equivalent to 'bagging_fraction'\n",
    "            colsample_bytree=0.8,      # Equivalent to 'feature_fraction'\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            verbose=-1                 # Suppress verbose output\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        # Convert to NumPy arrays before fitting and predicting\n",
    "        model.fit(X_train.to_numpy(), y_train.to_numpy().ravel())\n",
    "\n",
    "        predictions = model.predict(X_test.to_numpy())\n",
    "        signals = convert_to_signal(predictions)\n",
    "        score = calculate_competition_score(y_test_info, signals)\n",
    "        cv_scores.append(score)\n",
    "\n",
    "    mean_score = np.mean(cv_scores)\n",
    "    print(f\"\\nMean CV Score: {mean_score:.4f}, std: {np.std(cv_scores):.4f}\")\n",
    "    return mean_score\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example call to evaluate function\n",
    "    final_score = evaluate(0)\n",
    "    print(f\"Final Evaluation Score: {final_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
