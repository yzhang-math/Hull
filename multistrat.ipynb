{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0959d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# The training data path should be updated to your actual training file.\n",
    "TRAIN_DATA_PATH = \"./kaggle/train.csv\"\n",
    "SPY_DATA_PATH = \"./kaggle/spy-historical.csv\"\n",
    "\n",
    "def generate_features_7 (df: pl.DataFrame) -> pl.DataFrame:\n",
    "  \"\"\"Generates new features from the base data.\n",
    "    This function is the target of the evolutionary algorithm.\n",
    "  \n",
    "    Available Feature Categories:\n",
    "    - D* (Dummy/Binary features): 9 columns (D1-D9)\n",
    "    - E* (Macro Economic features): 20 columns (E1-E20)\n",
    "    - I* (Interest Rate features): 9 columns (I1-I9)\n",
    "    - M* (Market Dynamics/Technical features): 18 columns (M1-M18)\n",
    "    - P* (Price/Valuation features): 13 columns (P1-P13)\n",
    "    - S* (Sentiment features): 12 columns (S1-S12)\n",
    "    - V* (Volatility features): 13 columns (V1-V13)\n",
    "  \"\"\"\n",
    "  new_features = pl.DataFrame({\n",
    "      # --- 20 Pairwise Interactions ---\n",
    "      'feat_M1_x_V1': df['M1'] * df['V1'],\n",
    "      'feat_P1_add_E1': df['P1'] + df['E1'],\n",
    "      'feat_S1_sub_I1': df['S1'] - df['I1'],\n",
    "      'feat_M10_div_V10': df['M10'] / (df['V10'] + 1e-6),\n",
    "      'feat_P10_x_E10': df['P10'] * df['E10'],\n",
    "      'feat_M2_x_S3': df['M2'] * df['S3'],\n",
    "      'feat_V2_div_P2': df['V2'] / (df['P2'] + 1e-6),\n",
    "      'feat_E4_sub_I3': df['E4'] - df['I3'],\n",
    "      'feat_S7_add_M12': df['S7'] + df['M12'],\n",
    "      'feat_I5_x_V11': df['I5'] * df['V11'],\n",
    "      'feat_P5_div_S8': df['P5'] / (df['S8'] + 1e-6),\n",
    "      'feat_E12_x_I9': df['E12'] * df['I9'],\n",
    "      'feat_M1_div_S1': df['M1'] / (df['S1'] + 1e-6),\n",
    "      'feat_V1_add_P1': df['V1'] + df['P1'],\n",
    "      'feat_E1_sub_I1': df['E1'] - df['I1'],\n",
    "      'feat_M2_div_V2': df['M2'] / (df['V2'] + 1e-6),\n",
    "      'feat_P2_x_S3': df['P2'] * df['S3'],\n",
    "      'feat_E4_add_M10': df['E4'] + df['M10'],\n",
    "      'feat_I3_sub_V10': df['I3'] - df['V10'],\n",
    "      'feat_S7_x_P10': df['S7'] * df['P10'],\n",
    "      # --- 10 Rolling Window Features ---\n",
    "      'feat_V2_roll_mean_5': df['V2'].rolling_mean(window_size=5),\n",
    "      'feat_V1_roll_std_5': df['V1'].rolling_std(window_size=5),\n",
    "      'feat_M1_roll_mean_20': df['M1'].rolling_mean(window_size=20),\n",
    "      'feat_M3_roll_std_20': df['M3'].rolling_std(window_size=20),\n",
    "      'feat_P1_roll_max_10': df['P1'].rolling_max(window_size=10),\n",
    "      'feat_P1_roll_min_10': df['P1'].rolling_min(window_size=10),\n",
    "      'feat_E5_roll_mean_50': df['E5'].rolling_mean(window_size=50),\n",
    "      'feat_S1_roll_std_50': df['S1'].rolling_std(window_size=50),\n",
    "      'feat_I1_roll_mean_10': df['I1'].rolling_mean(window_size=10),\n",
    "      'feat_V10_roll_std_10': df['V10'].rolling_std(window_size=10),\n",
    "      # --- 10 Complex Interactions (3+ elements) ---\n",
    "      'feat_M1_V1_div_P1': (df['M1'] * df['V1']) / (df['P1'] + 1e-6),\n",
    "      'feat_E1_S1_add_I1': df['E1'] + df['S1'] - df['I1'],\n",
    "      'feat_M2_P2_sub_V2': df['M2'] + df['P2'] - df['V2'],\n",
    "      'feat_S7_div_E4_I3': df['S7'] / (df['E4'] + df['I3'] + 1e-6),\n",
    "      'feat_P5_x_M10_x_V10': df['P5'] * df['M10'] * df['V10'],\n",
    "      'feat_roll_diff_M1_5_20': df['M1'].rolling_mean(window_size=5) - df['M1'].rolling_mean(window_size=20),\n",
    "      'feat_roll_diff_V1_5_20': df['V1'].rolling_mean(window_size=5) - df['V1'].rolling_mean(window_size=20),\n",
    "      'feat_M_S_P_combo': (df['M12'] - df['M1']) / (df['S1'] + df['P1'] + 1e-6),\n",
    "      'feat_V_E_I_combo': (df['V11'] + df['V2']) * (df['E1'] - df['I1']),\n",
    "      'feat_ratio_of_ratios': (df['M1']/(df['V1']+1e-6)) / (df['P1']/(df['S1']+1e-6)),\n",
    "      # --- 10 New Features ---\n",
    "      'feat_M1_x_V1_x_P1': df['M1'] * df['V1'] * df['P1'],\n",
    "      'feat_E1_div_S1': df['E1'] / (df['S1'] + 1e-6),\n",
    "      'feat_I1_sub_V1': df['I1'] - df['V1'],\n",
    "      'feat_M10_add_V10': df['M10'] + df['V10'],\n",
    "      'feat_P10_div_E10': df['P10'] / (df['E10'] + 1e-6),\n",
    "      'feat_M2_add_S3': df['M2'] + df['S3'],\n",
    "      'feat_V2_x_P2': df['V2'] * df['P2'],\n",
    "      'feat_E4_add_I3': df['E4'] + df['I3'],\n",
    "      'feat_S7_div_M12': df['S7'] / (df['M12'] + 1e-6),\n",
    "      'feat_I5_div_V11': df['I5'] / (df['V11'] + 1e-6),\n",
    "      #'feat_M1_log_P1': np.log(df['M1'] + 1e-6) / np.log(df['P1'] + 1e-6),\n",
    "      # --- SAFER LOGIC HERE ---\n",
    "      #'feat_M1_log_P1': pl.when( (df['M1'] > 0) & (df['P1'] > 0) & (df['P1'] != 1) ).then( df['M1'].log() / df['P1'].log() ).otherwise(0),\n",
    "      # --- END SAFER LOGIC ---\n",
    "  })\n",
    "  # Fill any nulls created by rolling windows\n",
    "  return new_features.with_columns(pl.all().forward_fill())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56459772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solve: daily reranking\n",
    "\n",
    "def solve(df: pl.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Runs a time-series cross-validation process using a \"top-k leader\"\n",
    "    ensemble strategy with DAILY re-ranking.\n",
    "    \n",
    "    1. Trains N models at the start of each fold.\n",
    "    2. Iterates DAY-BY-DAY through the test set.\n",
    "    3. Each day, it finds the top k leaders based on the most recent \n",
    "       (e.g., 30-day) history.\n",
    "    4. It ensembles the positions from *only* those leaders for that day.\n",
    "    5. Appends the daily performance of ALL N strategies to the master \n",
    "       history to be used for the next day's ranking.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Ensemble Configuration ---\n",
    "    N_STRATEGIES = 50           # We'll create 10 strategies\n",
    "    SUBSAMPLE_RATIO = 0.05       # Each strategy sees 70% of the training data\n",
    "    FEATURE_GENERATOR = generate_features_7 # All strategies use this\n",
    "    \n",
    "    K_LEADERS = 3               # How many leaders to follow (e.g., 3)\n",
    "    ROLLING_WINDOW_DAYS = 50    # Lookback period to find leaders\n",
    "    MIN_HISTORY_DAYS = 25       # Min days needed to start picking leaders\n",
    "    TRADING_DAYS_PER_YR = 252\n",
    "\n",
    "    nsplits = 20\n",
    "\n",
    "    # --- Helper functions (unchanged) ---\n",
    "    \n",
    "    def calculate_competition_score(y_true_df: pl.DataFrame, y_pred_signals: np.ndarray) -> float:\n",
    "        ''' Calculates the competition score based on true values and predicted signals. '''\n",
    "        solution = y_true_df.to_pandas()\n",
    "        solution['position'] = y_pred_signals\n",
    "        solution['strategy_returns'] = (\n",
    "            solution['risk_free_rate'] * (1 - solution['position']) +\n",
    "            solution['position'] * solution['forward_returns']\n",
    "        )\n",
    "        strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate']\n",
    "        strategy_geo_mean = (1 + strategy_excess_returns).prod() ** (1 / len(solution)) - 1\n",
    "        strategy_std = solution['strategy_returns'].std()\n",
    "        if strategy_std == 0: return 0.0\n",
    "        \n",
    "        sharpe = strategy_geo_mean / strategy_std * np.sqrt(TRADING_DAYS_PER_YR)\n",
    "        market_std = solution['forward_returns'].std()\n",
    "        market_volatility = market_std * np.sqrt(TRADING_DAYS_PER_YR) * 100\n",
    "        strategy_volatility = strategy_std * np.sqrt(TRADING_DAYS_PER_YR) * 100\n",
    "        excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n",
    "        vol_penalty = 1 + excess_vol\n",
    "        market_excess_returns = solution['forward_returns'] - solution['risk_free_rate']\n",
    "        market_geo_mean = (1 + market_excess_returns).prod() ** (1 / len(solution)) - 1\n",
    "        return_gap = max(0, (market_geo_mean - strategy_geo_mean) * 100 * TRADING_DAYS_PER_YR)\n",
    "        return_penalty = 1 + (return_gap**2) / 100\n",
    "        adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n",
    "        print(f\"  Fold {i+1} (Daily): Strat Vol: {strategy_volatility:.2f}%, Mkt Vol: {market_volatility:.2f}%, Ret_penalty: {(return_penalty-1):.4f}, Sharpe: {sharpe:.4f}, Adj Sharpe: {adjusted_sharpe:.4f}\")\n",
    "        return adjusted_sharpe\n",
    "\n",
    "    def convert_to_signal(predictions: np.ndarray, multiplier: float = 400.0) -> np.ndarray:\n",
    "        ''' Converts raw model predictions into trading signals in the range [0, 2]. '''\n",
    "        signals = predictions * multiplier + 0.8\n",
    "        #signals = -np.abs(predictions-0.001) * 1000 + 3\n",
    "        return np.clip(signals, 0.0, 2.0)\n",
    "\n",
    "    def calculate_strategy_returns_pl(y_true_df_1_day: pl.DataFrame, y_pred_signal_1_day: np.ndarray) -> pl.Series:\n",
    "        \"\"\" Calculates strategy returns for a *single day*. \"\"\"\n",
    "        signals_series = pl.Series(\"position\", y_pred_signal_1_day)\n",
    "        df_with_pos = y_true_df_1_day.with_columns(signals_series)\n",
    "        strategy_returns = (\n",
    "            df_with_pos['risk_free_rate'] * (1 - df_with_pos['position']) +\n",
    "            df_with_pos['position'] * df_with_pos['forward_returns']\n",
    "        )\n",
    "        return strategy_returns.alias(\"strategy_returns\")\n",
    "\n",
    "    def calculate_sharpe_for_leaderboard(hist_window: pl.DataFrame, strategy_col: str) -> float:\n",
    "        \"\"\" Calculates the geometric Sharpe ratio for a single strategy from the history. \"\"\"\n",
    "        if hist_window.height == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        strategy_returns = hist_window[strategy_col]\n",
    "        risk_free_rate = hist_window['risk_free_rate']\n",
    "\n",
    "        market_excess_returns = (hist_window['forward_returns'] - hist_window['risk_free_rate']).to_pandas()\n",
    "        \n",
    "        strategy_excess_returns = (strategy_returns - risk_free_rate).to_numpy()\n",
    "        \n",
    "        if not np.all(np.isfinite(strategy_excess_returns)):\n",
    "            print(f\"Bad data for {strategy_col} in leaderboard calculation.\")\n",
    "            return -np.inf\n",
    "\n",
    "        log_returns = np.log1p(strategy_excess_returns)\n",
    "        strategy_geo_mean = np.exp(np.mean(log_returns)) - 1\n",
    "\n",
    "        strategy_std = strategy_returns.std()\n",
    "        \n",
    "        if strategy_std is None or strategy_std == 0 or not np.isfinite(strategy_std):\n",
    "            print(f\"Bad std for {strategy_col} in leaderboard calculation.\")\n",
    "            return 0.0\n",
    "            \n",
    "        sharpe = strategy_geo_mean / strategy_std * np.sqrt(TRADING_DAYS_PER_YR)\n",
    "\n",
    "        market_geo_mean = (1 + market_excess_returns).prod() ** (1 / len(market_excess_returns)) - 1\n",
    "        return_gap = max(0, (market_geo_mean - strategy_geo_mean) * 100 * TRADING_DAYS_PER_YR)\n",
    "        return_penalty = 1 + (return_gap**2) / 100\n",
    "\n",
    "        sharpe = sharpe/return_penalty\n",
    "        \n",
    "        return sharpe if np.isfinite(sharpe) else -np.inf\n",
    "\n",
    "    # --- Data Preparation (Efficient) ---\n",
    "    print(f\"Initial DataFrame shape: {df.shape}\")\n",
    "    base_df = df.rename({'market_forward_excess_returns': 'target'})\n",
    "    feature_cols = [col for col in base_df.columns if col != 'date_id']\n",
    "    base_df = base_df.with_columns(pl.col(feature_cols).cast(pl.Float64, strict=False))\n",
    "    \n",
    "    if 'E7' in base_df.columns:\n",
    "        base_df = base_df.drop('E7')\n",
    "        \n",
    "    base_df = base_df.with_columns(pl.all().forward_fill())\n",
    "    print(f\"Base DataFrame shape after cleaning: {base_df.shape}\")\n",
    "\n",
    "    # --- Generate ALL features ONCE ---\n",
    "    print(f\"Generating features using {FEATURE_GENERATOR.__name__}...\")\n",
    "    base_features = [col for col in base_df.columns if col not in [\"date_id\", \"forward_returns\", \"risk_free_rate\", \"target\"]]\n",
    "    new_features_df = FEATURE_GENERATOR(base_df)\n",
    "    \n",
    "    X_all_features = pl.concat([base_df.select(base_features), new_features_df], how=\"horizontal\")\n",
    "    X_all_features = base_df.select(base_features)\n",
    "    print(f\"Full feature set shape: {X_all_features.shape}\")\n",
    "\n",
    "    TARGET_COL = \"target\"\n",
    "    y = base_df.select(TARGET_COL)\n",
    "    scorer_info_df = base_df.select([\"date_id\", \"forward_returns\", \"risk_free_rate\"])\n",
    "\n",
    "    # --- Time-Series Cross-Validation ---\n",
    "    print(f\"Starting DAILY re-ranking CV with {N_STRATEGIES} strategies, following top {K_LEADERS} leaders.\")\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=nsplits)\n",
    "    \n",
    "    cv_scores = []\n",
    "    \n",
    "    # Master history of OOS performance for all N strategies\n",
    "    # This will be updated DAY-BY-DAY\n",
    "    history_df = pl.DataFrame()\n",
    "    \n",
    "    # Store final ensembled signals and truths for overall score\n",
    "    overall_final_signals = []\n",
    "    overall_y_true = []\n",
    "    \n",
    "    rng = np.random.default_rng(seed=12)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(tscv.split(base_df)):\n",
    "        print(f\"--- Starting Fold {i+1}/{nsplits} (Days {test_index[0]} to {test_index[-1]}) ---\")\n",
    "        \n",
    "        # Get the full train/test slices for this fold\n",
    "        X_train_fold_full = X_all_features[train_index]\n",
    "        y_train_fold_full = y[train_index]\n",
    "        \n",
    "        X_test_fold = X_all_features[test_index]\n",
    "        y_test_info_fold = scorer_info_df[test_index] # All \"truth\" data for this fold\n",
    "\n",
    "        # --- 1. Train N Models (Once per fold) ---\n",
    "        # print(\"  Training N models...\")\n",
    "        N_signals_fold = [] # Will store signals for all N models\n",
    "        n_samples = X_train_fold_full.height\n",
    "        subset_size = int(n_samples * SUBSAMPLE_RATIO)\n",
    "        \n",
    "        for j in range(N_STRATEGIES):\n",
    "            subset_fold_indices = rng.choice(n_samples, subset_size, replace=False)\n",
    "            X_train_j = X_train_fold_full[subset_fold_indices]\n",
    "            y_train_j = y_train_fold_full[subset_fold_indices]\n",
    "\n",
    "            model = xgb.XGBRegressor(\n",
    "                objective='reg:absoluteerror', n_estimators=5, device='cuda',\n",
    "                learning_rate=0.05, max_depth=4, subsample=0.8, colsample_bytree=0.8,\n",
    "                n_jobs=-1, random_state=42 + j \n",
    "            )\n",
    "            \n",
    "            model.fit(X_train_j, y_train_j, verbose=False)\n",
    "\n",
    "            # Predict on the *entire* test fold and store signals\n",
    "            predictions = model.predict(X_test_fold) \n",
    "            signals = convert_to_signal(predictions)\n",
    "            N_signals_fold.append(signals)\n",
    "            \n",
    "        # Stack into a [days, strategies] numpy array\n",
    "        N_signals_fold = np.stack(N_signals_fold, axis=1) \n",
    "        \n",
    "        # --- 2. Iterate Day-By-Day through the test fold ---\n",
    "        print(f\"  Iterating daily and re-ranking leaders...\")\n",
    "        \n",
    "        # Store the *final* ensembled signals for this fold\n",
    "        fold_ensembled_signals = [] \n",
    "\n",
    "        for day_idx in range(len(test_index)):\n",
    "            \n",
    "            # --- 2a. Find Top k Leaders (for today) ---\n",
    "            # Look at history *up to this point*\n",
    "            hist_window = history_df.tail(ROLLING_WINDOW_DAYS)\n",
    "            \n",
    "            if hist_window.height < MIN_HISTORY_DAYS:\n",
    "                # Not enough history, average all strategies\n",
    "                leaderboard = None\n",
    "                top_k_indices = list(range(N_STRATEGIES))\n",
    "                if day_idx % 20 == 0: # Print status periodically\n",
    "                   print(f\"    Day {day_idx}: Not enough history, averaging all {N_STRATEGIES}.\")\n",
    "            else:\n",
    "                # We have history, find the leaders\n",
    "                leaderboard = []\n",
    "                for j in range(N_STRATEGIES):\n",
    "                    sharpe = calculate_sharpe_for_leaderboard(hist_window, f'returns_{j}')\n",
    "                    leaderboard.append((sharpe, j))\n",
    "                \n",
    "                leaderboard.sort(key=lambda x: x[0], reverse=True)\n",
    "                top_k_indices = [j for sharpe, j in leaderboard[:K_LEADERS]]\n",
    "                if day_idx % 20 == 0: # Print status periodically\n",
    "                    print(f\"    Day {day_idx}: Top {K_LEADERS} leaders: {top_k_indices}, Sharpes: {[f'{s:.3f}' for s, j in leaderboard[:K_LEADERS]]}\")\n",
    "\n",
    "            # --- 2b. Ensemble Position (for today) ---\n",
    "            # Get the pre-calculated signals for *all N* strategies *for today*\n",
    "            today_N_signals = N_signals_fold[day_idx, :]\n",
    "            \n",
    "            # Get signals from *only* the leaders\n",
    "            signals_from_leaders = today_N_signals[top_k_indices]\n",
    "            \n",
    "            # Average them to get the final position\n",
    "            final_signal_today = np.mean(signals_from_leaders[0:2])\n",
    "\n",
    "            # default to const strategy if no strategy is doing good enough.\n",
    "\n",
    "            if leaderboard and leaderboard[0][0] < -0.2:\n",
    "                final_signal_today = 0.8\n",
    "\n",
    "            fold_ensembled_signals.append(final_signal_today)\n",
    "\n",
    "            # --- 2c. Update Master History (for tomorrow's ranking) ---\n",
    "            # Get today's \"truth\" data (1-row DataFrame)\n",
    "            today_test_info = y_test_info_fold[day_idx]\n",
    "            \n",
    "            # Calculate the returns for *all N* individual strategies for today\n",
    "            today_returns_N = []\n",
    "            for j in range(N_STRATEGIES):\n",
    "                signal_j_today = np.array([today_N_signals[j]])\n",
    "                return_j_series = calculate_strategy_returns_pl(today_test_info, signal_j_today)\n",
    "                today_returns_N.append(return_j_series[0]) # Get the single float value\n",
    "            \n",
    "            # Build the new history row\n",
    "            new_history_row_data = {\n",
    "                \"date_id\": today_test_info[\"date_id\"][0],\n",
    "                \"forward_returns\": today_test_info[\"forward_returns\"][0],\n",
    "                \"risk_free_rate\": today_test_info[\"risk_free_rate\"][0],\n",
    "                **{f\"returns_{j}\": ret for j, ret in enumerate(today_returns_N)}\n",
    "            }\n",
    "            new_history_row_df = pl.DataFrame(new_history_row_data)\n",
    "\n",
    "            # Append to the master history_df\n",
    "            history_df = pl.concat([history_df, new_history_row_df])\n",
    "\n",
    "        # --- 3. Score Fold (after iterating all days) ---\n",
    "        print(\"  Fold iteration complete. Scoring fold...\")\n",
    "        fold_final_signals_arr = np.array(fold_ensembled_signals)\n",
    "        score = calculate_competition_score(y_test_info_fold, fold_final_signals_arr)\n",
    "        cv_scores.append(score)\n",
    "        \n",
    "        # Store for overall score calculation\n",
    "        overall_final_signals.append(fold_final_signals_arr)\n",
    "        overall_y_true.append(y_test_info_fold)\n",
    "\n",
    "    # --- 4. Final Evaluation ---\n",
    "    mean_score = np.mean(cv_scores)\n",
    "    print(f\"\\n--- CV Finished ---\")\n",
    "    print(f\"Mean Ensembled CV Score (Daily Re-ranking): {mean_score:.4f}, std: {np.std(cv_scores):.4f}\")\n",
    "    \n",
    "    overall_y_true_df = pl.concat(overall_y_true)\n",
    "    overall_final_signals_arr = np.concatenate(overall_final_signals)\n",
    "    \n",
    "    print(\"\\n--- Overall OOS Performance (Daily Re-ranking) ---\")\n",
    "    # This score is the most important one\n",
    "    overall_score = calculate_competition_score(overall_y_true_df, overall_final_signals_arr)\n",
    "    print(f\" Overall Ensembled Score: {overall_score:.4f}\")\n",
    "    \n",
    "    return overall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e0b2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: add constant strategy and other basic strategies (ma5/20, rsi, ...) to pool\n",
    "# todo:  \n",
    "# todo: weighted position\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# ... (Previous imports and generate_features_7 function remain unchanged) ...\n",
    "\n",
    "def solve(df: pl.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Runs a time-series cross-validation process using a \"top-k leader\"\n",
    "    ensemble strategy with DAILY re-ranking.\n",
    "    \n",
    "    MODIFICATION: Uses iterative data pruning (semi-deterministic).\n",
    "    After training a strategy, data points that were 'well-predicted' \n",
    "    (low error) are removed from the training set for the next strategy.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Ensemble Configuration ---\n",
    "    N_STRATEGIES = 50           \n",
    "    SUBSAMPLE_RATIO = 0.05       # Increased slightly to ensure coverage as we shrink data\n",
    "    FEATURE_GENERATOR = generate_features_7 \n",
    "    \n",
    "    K_LEADERS = 2               \n",
    "    ROLLING_WINDOW_DAYS = 50    \n",
    "    MIN_HISTORY_DAYS = 15       \n",
    "    TRADING_DAYS_PER_YR = 252\n",
    "\n",
    "    # Percentage of \"easiest\" data points to remove after each strategy\n",
    "    # i.e., remove the 15% of rows with the lowest absolute error\n",
    "    PRUNE_PERCENTILE = 15       \n",
    "\n",
    "    nsplits = 20\n",
    "\n",
    "    # --- Helper functions (same as before) ---\n",
    "    def calculate_competition_score(y_true_df: pl.DataFrame, y_pred_signals: np.ndarray) -> float:\n",
    "        ''' Calculates the competition score based on true values and predicted signals. '''\n",
    "        solution = y_true_df.to_pandas()\n",
    "        solution['position'] = y_pred_signals\n",
    "        solution['strategy_returns'] = (\n",
    "            solution['risk_free_rate'] * (1 - solution['position']) +\n",
    "            solution['position'] * solution['forward_returns']\n",
    "        )\n",
    "        strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate']\n",
    "        strategy_geo_mean = (1 + strategy_excess_returns).prod() ** (1 / len(solution)) - 1\n",
    "        strategy_std = solution['strategy_returns'].std()\n",
    "        if strategy_std == 0: return 0.0\n",
    "        \n",
    "        sharpe = strategy_geo_mean / strategy_std * np.sqrt(TRADING_DAYS_PER_YR)\n",
    "        market_std = solution['forward_returns'].std()\n",
    "        market_volatility = market_std * np.sqrt(TRADING_DAYS_PER_YR) * 100\n",
    "        strategy_volatility = strategy_std * np.sqrt(TRADING_DAYS_PER_YR) * 100\n",
    "        excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n",
    "        vol_penalty = 1 + excess_vol\n",
    "        market_excess_returns = solution['forward_returns'] - solution['risk_free_rate']\n",
    "        market_geo_mean = (1 + market_excess_returns).prod() ** (1 / len(solution)) - 1\n",
    "        return_gap = max(0, (market_geo_mean - strategy_geo_mean) * 100 * TRADING_DAYS_PER_YR)\n",
    "        return_penalty = 1 + (return_gap**2) / 100\n",
    "        adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n",
    "        print(f\"  Fold {i+1} (Daily): Strat Vol: {strategy_volatility:.2f}%, Mkt Vol: {market_volatility:.2f}%, Ret_penalty: {(return_penalty-1):.4f}, Sharpe: {sharpe:.4f}, Adj Sharpe: {adjusted_sharpe:.4f}\")\n",
    "        return adjusted_sharpe\n",
    "\n",
    "    def convert_to_signal(predictions: np.ndarray, multiplier: float = 400.0) -> np.ndarray:\n",
    "        signals = predictions * multiplier + 0.9\n",
    "        #signals = -np.abs(predictions-0.001) * 1000 + 3\n",
    "        return np.clip(signals, 0.0, 2.0)\n",
    "\n",
    "    def calculate_strategy_returns_pl(y_true_df_1_day: pl.DataFrame, y_pred_signal_1_day: np.ndarray) -> pl.Series:\n",
    "        signals_series = pl.Series(\"position\", y_pred_signal_1_day)\n",
    "        df_with_pos = y_true_df_1_day.with_columns(signals_series)\n",
    "        strategy_returns = (\n",
    "            df_with_pos['risk_free_rate'] * (1 - df_with_pos['position']) +\n",
    "            df_with_pos['position'] * df_with_pos['forward_returns']\n",
    "        )\n",
    "        return strategy_returns.alias(\"strategy_returns\")\n",
    "\n",
    "    def calculate_sharpe_for_leaderboard(hist_window: pl.DataFrame, strategy_col: str) -> float:\n",
    "        if hist_window.height == 0: return 0.0\n",
    "        strategy_returns = hist_window[strategy_col]\n",
    "        risk_free_rate = hist_window['risk_free_rate']\n",
    "        strategy_excess_returns = (strategy_returns - risk_free_rate).to_numpy()\n",
    "        if not np.all(np.isfinite(strategy_excess_returns)): return -np.inf\n",
    "        log_returns = np.log1p(strategy_excess_returns)\n",
    "        strategy_geo_mean = np.exp(np.mean(log_returns)) - 1\n",
    "        strategy_std = strategy_returns.std()\n",
    "        if strategy_std is None or strategy_std == 0 or not np.isfinite(strategy_std): return 0.0\n",
    "        sharpe = strategy_geo_mean / strategy_std * np.sqrt(TRADING_DAYS_PER_YR)\n",
    "        return sharpe if np.isfinite(sharpe) else -np.inf\n",
    "\n",
    "    # --- Data Preparation ---\n",
    "    print(f\"Initial DataFrame shape: {df.shape}\")\n",
    "    base_df = df.rename({'market_forward_excess_returns': 'target'})\n",
    "    feature_cols = [col for col in base_df.columns if col != 'date_id']\n",
    "    base_df = base_df.with_columns(pl.col(feature_cols).cast(pl.Float64, strict=False))\n",
    "    if 'E7' in base_df.columns: base_df = base_df.drop('E7')\n",
    "    base_df = base_df.with_columns(pl.all().forward_fill())\n",
    "    \n",
    "    print(f\"Generating features using {FEATURE_GENERATOR.__name__}...\")\n",
    "    base_features = [col for col in base_df.columns if col not in [\"date_id\", \"forward_returns\", \"risk_free_rate\", \"target\"]]\n",
    "    new_features_df = FEATURE_GENERATOR(base_df)\n",
    "    X_all_features = pl.concat([base_df.select(base_features), new_features_df], how=\"horizontal\")\n",
    "    print(f\"Full feature set shape: {X_all_features.shape}\")\n",
    "\n",
    "    TARGET_COL = \"target\"\n",
    "    y = base_df.select(TARGET_COL)\n",
    "    scorer_info_df = base_df.select([\"date_id\", \"forward_returns\", \"risk_free_rate\"])\n",
    "\n",
    "    print(f\"Starting DAILY re-ranking CV with {N_STRATEGIES} strategies, following top {K_LEADERS} leaders.\")\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=nsplits)\n",
    "    cv_scores = []\n",
    "    history_df = pl.DataFrame()\n",
    "    overall_final_signals = []\n",
    "    overall_y_true = []\n",
    "    \n",
    "    rng = np.random.default_rng(seed=12)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(tscv.split(base_df)):\n",
    "        print(f\"--- Starting Fold {i+1}/{nsplits} (Days {test_index[0]} to {test_index[-1]}) ---\\n\")\n",
    "        \n",
    "        # Slices for test\n",
    "        X_test_fold = X_all_features[test_index]\n",
    "        y_test_info_fold = scorer_info_df[test_index]\n",
    "\n",
    "        # --- 1. Semi-Deterministic Iterative Training ---\n",
    "        N_signals_fold = [] \n",
    "        \n",
    "        # Initialize the pool of available training indices for this fold\n",
    "        # (We convert to a numpy array to make filtering easier)\n",
    "        available_train_indices = np.array(train_index)\n",
    "        \n",
    "        for j in range(N_STRATEGIES):\n",
    "            current_pool_size = len(available_train_indices)\n",
    "            \n",
    "            # Safety check: if we pruned too much, reset to full random sample\n",
    "            if current_pool_size < 200: \n",
    "                # Fallback: Just sample from original train_index\n",
    "                subset_indices = rng.choice(train_index, int(len(train_index)*SUBSAMPLE_RATIO), replace=False)\n",
    "            else:\n",
    "                # Subsample from the REMAINING filtered pool\n",
    "                sample_size = int(current_pool_size * SUBSAMPLE_RATIO)\n",
    "                subset_indices = rng.choice(available_train_indices, sample_size, replace=False)\n",
    "\n",
    "            X_train_j = X_all_features[subset_indices]\n",
    "            y_train_j = y[subset_indices]\n",
    "\n",
    "            model = xgb.XGBRegressor(\n",
    "                objective='reg:absoluteerror', n_estimators=10, device='cuda',\n",
    "                learning_rate=0.05, max_depth=4, subsample=0.8, colsample_bytree=0.8,\n",
    "                n_jobs=-1, random_state=42 + j \n",
    "            )\n",
    "            \n",
    "            model.fit(X_train_j, y_train_j, verbose=False)\n",
    "\n",
    "            # Store predictions for the test fold\n",
    "            predictions_test = model.predict(X_test_fold) \n",
    "            signals = convert_to_signal(predictions_test)\n",
    "            N_signals_fold.append(signals)\n",
    "\n",
    "            # --- DATA PRUNING LOGIC ---\n",
    "            # 1. Predict on the *entire* currently available training pool\n",
    "            X_eval_pool = X_all_features[available_train_indices]\n",
    "            y_eval_pool = y[available_train_indices].to_numpy().flatten()\n",
    "            \n",
    "            preds_pool = model.predict(X_eval_pool)\n",
    "            \n",
    "            # 2. Calculate Absolute Error\n",
    "            # Low error = \"Close to Market\" / Model solved these days\n",
    "            errors = np.abs(preds_pool - y_eval_pool)\n",
    "            \n",
    "            # 3. Determine threshold (e.g., the bottom 15% errors are considered \"solved\")\n",
    "            error_threshold = np.percentile(errors, PRUNE_PERCENTILE)\n",
    "            \n",
    "            # 4. Filter: Keep only the rows where the error is HIGH (Model struggled)\n",
    "            # This forces the next model to learn the \"hard\" cases.\n",
    "            keep_mask = errors > error_threshold\n",
    "            available_train_indices = available_train_indices[keep_mask]\n",
    "            \n",
    "            # Optional: Debug print to see pool shrinking\n",
    "            # if j % 3 == 0:\n",
    "            #     print(f\"    Strat {j}: Pool size {current_pool_size} -> {len(available_train_indices)} (removed solved dates)\")\n",
    "\n",
    "        N_signals_fold = np.stack(N_signals_fold, axis=1) \n",
    "        \n",
    "        # --- 2. Iterate Day-By-Day (Unchanged) ---\n",
    "        # print(f\"  Iterating daily and re-ranking leaders...\")\n",
    "        fold_ensembled_signals = [] \n",
    "\n",
    "        for day_idx in range(len(test_index)):\n",
    "            hist_window = history_df.tail(ROLLING_WINDOW_DAYS)\n",
    "            \n",
    "            if hist_window.height < MIN_HISTORY_DAYS:\n",
    "                leaderboard = []\n",
    "                top_k_indices = list(range(N_STRATEGIES))\n",
    "            else:\n",
    "                leaderboard = []\n",
    "                for j in range(N_STRATEGIES):\n",
    "                    sharpe = calculate_sharpe_for_leaderboard(hist_window, f'returns_{j}')\n",
    "                    leaderboard.append((sharpe, j))\n",
    "                \n",
    "                leaderboard.sort(key=lambda x: x[0], reverse=True)\n",
    "                top_k_indices = [j for sharpe, j in leaderboard[:K_LEADERS]]\n",
    "\n",
    "            today_N_signals = N_signals_fold[day_idx, :]\n",
    "            signals_from_leaders = today_N_signals[top_k_indices]\n",
    "            final_signal_today = np.mean(signals_from_leaders)\n",
    "\n",
    "            if leaderboard and day_idx % 60 == 0: # Print status periodically\n",
    "                    print(f\"    Day {day_idx}: Top {K_LEADERS} leaders: {top_k_indices}, Sharpes: {[f'{s:.3f}' for s, j in leaderboard[:K_LEADERS]]}\")\n",
    "\n",
    "            # --- 2b. Ensemble Position (for today) ---\n",
    "\n",
    "            if leaderboard and leaderboard[0][0] < -1:\n",
    "                final_signal_today = 0.5\n",
    "\n",
    "            fold_ensembled_signals.append(final_signal_today)\n",
    "\n",
    "            today_test_info = y_test_info_fold[day_idx]\n",
    "            today_returns_N = []\n",
    "            for j in range(N_STRATEGIES):\n",
    "                signal_j_today = np.array([today_N_signals[j]])\n",
    "                return_j_series = calculate_strategy_returns_pl(today_test_info, signal_j_today)\n",
    "                today_returns_N.append(return_j_series[0]) \n",
    "            \n",
    "            new_history_row_data = {\n",
    "                \"date_id\": today_test_info[\"date_id\"][0],\n",
    "                \"forward_returns\": today_test_info[\"forward_returns\"][0],\n",
    "                \"risk_free_rate\": today_test_info[\"risk_free_rate\"][0],\n",
    "                **{f\"returns_{j}\": ret for j, ret in enumerate(today_returns_N)}\n",
    "            }\n",
    "            history_df = pl.concat([history_df, pl.DataFrame(new_history_row_data)])\n",
    "\n",
    "        # --- 3. Score Fold ---\n",
    "        fold_final_signals_arr = np.array(fold_ensembled_signals)\n",
    "        score = calculate_competition_score(y_test_info_fold, fold_final_signals_arr)\n",
    "        cv_scores.append(score)\n",
    "        \n",
    "        overall_final_signals.append(fold_final_signals_arr)\n",
    "        overall_y_true.append(y_test_info_fold)\n",
    "\n",
    "    # --- 4. Final Evaluation ---\n",
    "    mean_score = np.mean(cv_scores)\n",
    "    print(f\"\\n--- CV Finished ---\")\n",
    "    print(f\"Mean Ensembled CV Score (Daily Re-ranking): {mean_score:.4f}, std: {np.std(cv_scores):.4f}\")\n",
    "    \n",
    "    overall_y_true_df = pl.concat(overall_y_true)\n",
    "    overall_final_signals_arr = np.concatenate(overall_final_signals)\n",
    "    \n",
    "    print(\"\\n--- Overall OOS Performance (Daily Re-ranking) ---\")\n",
    "    overall_score = calculate_competition_score(overall_y_true_df, overall_final_signals_arr)\n",
    "    print(f\" Overall Ensembled Score: {overall_score:.4f}\")\n",
    "    \n",
    "    return overall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51d9829f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4990, 98)\n",
      "\n",
      "--- Joining weekday feature onto sliced data ---\n",
      "Initial DataFrame shape: (4990, 99)\n",
      "Base DataFrame shape after cleaning: (4990, 98)\n",
      "Generating features using generate_features_7...\n",
      "Full feature set shape: (4990, 94)\n",
      "Starting DAILY re-ranking CV with 50 strategies, following top 3 leaders.\n",
      "--- Starting Fold 1/20 (Days 250 to 486) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14245/1214272047.py:17: DeprecationWarning: the argument `min_periods` for `Expr.rolling_mean` is deprecated. It was renamed to `min_samples` in version 1.21.0.\n",
      "  pl.selectors.numeric().rolling_mean(window_size=5, min_periods=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Not enough history, averaging all 50.\n",
      "    Day 20: Not enough history, averaging all 50.\n",
      "    Day 40: Top 3 leaders: [41, 16, 29], Sharpes: ['2.942', '2.584', '2.406']\n",
      "    Day 60: Top 3 leaders: [29, 41, 16], Sharpes: ['4.181', '3.527', '2.868']\n",
      "    Day 80: Top 3 leaders: [8, 1, 33], Sharpes: ['0.635', '0.407', '0.305']\n",
      "    Day 100: Top 3 leaders: [46, 8, 49], Sharpes: ['2.498', '2.007', '1.436']\n",
      "    Day 120: Top 3 leaders: [8, 46, 1], Sharpes: ['3.709', '2.465', '2.141']\n",
      "    Day 140: Top 3 leaders: [40, 38, 18], Sharpes: ['4.613', '4.373', '4.353']\n",
      "    Day 160: Top 3 leaders: [10, 46, 41], Sharpes: ['3.240', '2.307', '2.236']\n",
      "    Day 180: Top 3 leaders: [10, 25, 24], Sharpes: ['3.131', '0.470', '0.078']\n",
      "    Day 200: Top 3 leaders: [32, 10, 25], Sharpes: ['2.319', '1.197', '0.887']\n",
      "    Day 220: Top 3 leaders: [10, 46, 48], Sharpes: ['1.055', '0.809', '0.673']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 1 (Daily): Strat Vol: 7.09%, Mkt Vol: 13.21%, Ret_penalty: 1.6218, Sharpe: -0.5730, Adj Sharpe: -0.2185\n",
      "--- Starting Fold 2/20 (Days 487 to 723) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [10, 48, 46], Sharpes: ['2.065', '1.882', '1.759']\n",
      "    Day 20: Top 3 leaders: [29, 44, 33], Sharpes: ['2.098', '1.743', '1.613']\n",
      "    Day 40: Top 3 leaders: [33, 29, 11], Sharpes: ['1.346', '0.704', '0.349']\n",
      "    Day 60: Top 3 leaders: [33, 29, 27], Sharpes: ['1.145', '0.088', '-0.062']\n",
      "    Day 80: Top 3 leaders: [29, 28, 12], Sharpes: ['0.342', '-0.095', '-0.097']\n",
      "    Day 100: Top 3 leaders: [20, 12, 31], Sharpes: ['-0.075', '-0.075', '-0.081']\n",
      "    Day 120: Top 3 leaders: [30, 29, 43], Sharpes: ['1.391', '0.946', '0.628']\n",
      "    Day 140: Top 3 leaders: [30, 29, 43], Sharpes: ['1.780', '1.147', '1.087']\n",
      "    Day 160: Top 3 leaders: [29, 18, 39], Sharpes: ['2.467', '1.808', '1.717']\n",
      "    Day 180: Top 3 leaders: [33, 31, 5], Sharpes: ['2.027', '-0.112', '-0.112']\n",
      "    Day 200: Top 3 leaders: [1, 0, 33], Sharpes: ['2.185', '1.183', '0.964']\n",
      "    Day 220: Top 3 leaders: [0, 27, 29], Sharpes: ['3.101', '1.201', '0.821']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 2 (Daily): Strat Vol: 19.35%, Mkt Vol: 21.92%, Ret_penalty: 0.0000, Sharpe: -0.5730, Adj Sharpe: -0.5730\n",
      "--- Starting Fold 3/20 (Days 724 to 960) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [27, 40, 29], Sharpes: ['1.736', '1.571', '1.459']\n",
      "    Day 20: Top 3 leaders: [11, 28, 31], Sharpes: ['-0.027', '-0.037', '-0.037']\n",
      "    Day 40: Top 3 leaders: [11, 30, 39], Sharpes: ['-0.013', '-0.024', '-0.025']\n",
      "    Day 60: Top 3 leaders: [24, 27, 37], Sharpes: ['1.757', '1.692', '1.614']\n",
      "    Day 80: Top 3 leaders: [24, 0, 34], Sharpes: ['2.097', '1.317', '1.302']\n",
      "    Day 100: Top 3 leaders: [0, 24, 17], Sharpes: ['1.592', '0.511', '0.457']\n",
      "    Day 120: Top 3 leaders: [17, 24, 1], Sharpes: ['0.893', '0.393', '0.124']\n",
      "    Day 140: Top 3 leaders: [36, 1, 0], Sharpes: ['2.185', '2.044', '1.965']\n",
      "    Day 160: Top 3 leaders: [16, 48, 25], Sharpes: ['4.989', '4.737', '4.737']\n",
      "    Day 180: Top 3 leaders: [16, 47, 14], Sharpes: ['5.135', '4.021', '3.845']\n",
      "    Day 200: Top 3 leaders: [7, 17, 6], Sharpes: ['3.318', '3.073', '2.375']\n",
      "    Day 220: Top 3 leaders: [41, 6, 39], Sharpes: ['4.361', '3.517', '3.415']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 3 (Daily): Strat Vol: 33.50%, Mkt Vol: 33.66%, Ret_penalty: 0.0000, Sharpe: 0.4777, Adj Sharpe: 0.4777\n",
      "--- Starting Fold 4/20 (Days 961 to 1197) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [9, 18, 46], Sharpes: ['4.660', '4.574', '4.030']\n",
      "    Day 20: Top 3 leaders: [48, 29, 9], Sharpes: ['3.517', '3.417', '2.966']\n",
      "    Day 40: Top 3 leaders: [49, 0, 48], Sharpes: ['2.636', '2.505', '2.466']\n",
      "    Day 60: Top 3 leaders: [49, 0, 17], Sharpes: ['3.064', '2.459', '2.083']\n",
      "    Day 80: Top 3 leaders: [0, 34, 49], Sharpes: ['2.377', '2.047', '1.971']\n",
      "    Day 100: Top 3 leaders: [15, 43, 35], Sharpes: ['0.828', '0.351', '0.038']\n",
      "    Day 120: Top 3 leaders: [28, 12, 48], Sharpes: ['1.762', '1.536', '1.281']\n",
      "    Day 140: Top 3 leaders: [28, 1, 12], Sharpes: ['2.725', '2.362', '2.292']\n",
      "    Day 160: Top 3 leaders: [33, 42, 20], Sharpes: ['6.344', '5.495', '5.043']\n",
      "    Day 180: Top 3 leaders: [48, 49, 24], Sharpes: ['1.777', '1.237', '0.893']\n",
      "    Day 200: Top 3 leaders: [49, 24, 44], Sharpes: ['1.327', '1.024', '0.680']\n",
      "    Day 220: Top 3 leaders: [49, 1, 15], Sharpes: ['1.520', '1.225', '0.490']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 4 (Daily): Strat Vol: 13.95%, Mkt Vol: 18.61%, Ret_penalty: 3.2117, Sharpe: -0.7298, Adj Sharpe: -0.1733\n",
      "--- Starting Fold 5/20 (Days 1198 to 1434) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [28, 45, 10], Sharpes: ['2.207', '1.722', '1.447']\n",
      "    Day 20: Top 3 leaders: [28, 16, 11], Sharpes: ['3.454', '3.359', '3.261']\n",
      "    Day 40: Top 3 leaders: [45, 43, 29], Sharpes: ['4.126', '3.233', '2.869']\n",
      "    Day 60: Top 3 leaders: [4, 42, 29], Sharpes: ['6.513', '6.185', '6.098']\n",
      "    Day 80: Top 3 leaders: [19, 4, 22], Sharpes: ['4.540', '4.229', '3.847']\n",
      "    Day 100: Top 3 leaders: [20, 4, 19], Sharpes: ['4.905', '4.528', '4.406']\n",
      "    Day 120: Top 3 leaders: [28, 29, 4], Sharpes: ['6.272', '6.270', '6.010']\n",
      "    Day 140: Top 3 leaders: [31, 43, 22], Sharpes: ['4.446', '3.940', '3.520']\n",
      "    Day 160: Top 3 leaders: [22, 1, 9], Sharpes: ['3.850', '3.650', '3.426']\n",
      "    Day 180: Top 3 leaders: [1, 22, 9], Sharpes: ['3.172', '2.934', '2.822']\n",
      "    Day 200: Top 3 leaders: [8, 43, 7], Sharpes: ['3.268', '2.394', '2.389']\n",
      "    Day 220: Top 3 leaders: [15, 34, 17], Sharpes: ['2.069', '1.860', '1.793']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 5 (Daily): Strat Vol: 9.92%, Mkt Vol: 13.14%, Ret_penalty: 0.5996, Sharpe: 1.6969, Adj Sharpe: 1.0608\n",
      "--- Starting Fold 6/20 (Days 1435 to 1671) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [12, 16, 45], Sharpes: ['1.143', '0.903', '0.899']\n",
      "    Day 20: Top 3 leaders: [33, 40, 21], Sharpes: ['1.748', '1.549', '1.054']\n",
      "    Day 40: Top 3 leaders: [40, 19, 7], Sharpes: ['1.425', '1.262', '1.136']\n",
      "    Day 60: Top 3 leaders: [7, 49, 19], Sharpes: ['4.132', '3.188', '2.974']\n",
      "    Day 80: Top 3 leaders: [2, 34, 7], Sharpes: ['3.249', '3.213', '3.111']\n",
      "    Day 100: Top 3 leaders: [34, 30, 32], Sharpes: ['4.101', '3.319', '3.270']\n",
      "    Day 120: Top 3 leaders: [32, 30, 36], Sharpes: ['4.740', '3.875', '2.514']\n",
      "    Day 140: Top 3 leaders: [9, 8, 39], Sharpes: ['5.781', '4.582', '4.284']\n",
      "    Day 160: Top 3 leaders: [7, 17, 46], Sharpes: ['6.176', '6.175', '6.075']\n",
      "    Day 180: Top 3 leaders: [7, 42, 17], Sharpes: ['3.902', '3.674', '3.287']\n",
      "    Day 200: Top 3 leaders: [33, 25, 2], Sharpes: ['4.290', '2.382', '1.332']\n",
      "    Day 220: Top 3 leaders: [33, 30, 25], Sharpes: ['1.138', '-0.047', '-0.131']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 6 (Daily): Strat Vol: 12.35%, Mkt Vol: 22.43%, Ret_penalty: 0.0792, Sharpe: 0.4088, Adj Sharpe: 0.3788\n",
      "--- Starting Fold 7/20 (Days 1672 to 1908) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [25, 40, 38], Sharpes: ['1.399', '1.286', '1.130']\n",
      "    Day 20: Top 3 leaders: [47, 29, 25], Sharpes: ['3.924', '3.501', '3.374']\n",
      "    Day 40: Top 3 leaders: [40, 25, 39], Sharpes: ['4.081', '3.456', '2.967']\n",
      "    Day 60: Top 3 leaders: [29, 40, 14], Sharpes: ['3.252', '3.210', '3.074']\n",
      "    Day 80: Top 3 leaders: [31, 9, 21], Sharpes: ['1.562', '1.395', '1.345']\n",
      "    Day 100: Top 3 leaders: [13, 46, 45], Sharpes: ['1.338', '0.898', '0.660']\n",
      "    Day 120: Top 3 leaders: [45, 13, 49], Sharpes: ['2.244', '1.957', '1.253']\n",
      "    Day 140: Top 3 leaders: [29, 49, 0], Sharpes: ['4.211', '4.131', '4.101']\n",
      "    Day 160: Top 3 leaders: [48, 29, 37], Sharpes: ['3.861', '3.620', '3.580']\n",
      "    Day 180: Top 3 leaders: [34, 31, 14], Sharpes: ['4.270', '4.237', '3.988']\n",
      "    Day 200: Top 3 leaders: [20, 42, 16], Sharpes: ['5.064', '3.272', '2.379']\n",
      "    Day 220: Top 3 leaders: [49, 8, 30], Sharpes: ['4.574', '4.236', '3.992']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 7 (Daily): Strat Vol: 9.02%, Mkt Vol: 11.85%, Ret_penalty: 3.0876, Sharpe: 0.4208, Adj Sharpe: 0.1030\n",
      "--- Starting Fold 8/20 (Days 1909 to 2145) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [6, 8, 28], Sharpes: ['3.914', '3.677', '3.369']\n",
      "    Day 20: Top 3 leaders: [8, 23, 28], Sharpes: ['4.829', '3.674', '3.508']\n",
      "    Day 40: Top 3 leaders: [8, 20, 23], Sharpes: ['3.383', '2.629', '2.438']\n",
      "    Day 60: Top 3 leaders: [29, 4, 24], Sharpes: ['4.054', '3.935', '3.902']\n",
      "    Day 80: Top 3 leaders: [4, 14, 22], Sharpes: ['2.674', '1.811', '1.313']\n",
      "    Day 100: Top 3 leaders: [4, 39, 44], Sharpes: ['4.241', '3.808', '3.686']\n",
      "    Day 120: Top 3 leaders: [5, 39, 46], Sharpes: ['4.513', '3.667', '3.411']\n",
      "    Day 140: Top 3 leaders: [25, 19, 20], Sharpes: ['4.734', '3.832', '3.730']\n",
      "    Day 160: Top 3 leaders: [5, 21, 32], Sharpes: ['3.810', '3.232', '3.161']\n",
      "    Day 180: Top 3 leaders: [5, 1, 48], Sharpes: ['4.315', '3.588', '2.581']\n",
      "    Day 200: Top 3 leaders: [5, 1, 24], Sharpes: ['3.836', '3.118', '2.297']\n",
      "    Day 220: Top 3 leaders: [11, 33, 45], Sharpes: ['4.123', '2.985', '2.522']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 8 (Daily): Strat Vol: 7.76%, Mkt Vol: 10.99%, Ret_penalty: 1.1517, Sharpe: 0.8557, Adj Sharpe: 0.3977\n",
      "--- Starting Fold 9/20 (Days 2146 to 2382) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [11, 3, 33], Sharpes: ['3.132', '2.831', '2.616']\n",
      "    Day 20: Top 3 leaders: [8, 24, 5], Sharpes: ['5.779', '5.598', '5.244']\n",
      "    Day 40: Top 3 leaders: [47, 24, 34], Sharpes: ['4.550', '4.237', '4.115']\n",
      "    Day 60: Top 3 leaders: [46, 39, 20], Sharpes: ['3.327', '2.032', '1.704']\n",
      "    Day 80: Top 3 leaders: [46, 39, 37], Sharpes: ['4.047', '2.244', '1.932']\n",
      "    Day 100: Top 3 leaders: [21, 45, 11], Sharpes: ['2.979', '2.446', '1.605']\n",
      "    Day 120: Top 3 leaders: [21, 24, 23], Sharpes: ['3.223', '2.758', '2.154']\n",
      "    Day 140: Top 3 leaders: [24, 21, 2], Sharpes: ['3.872', '2.498', '2.202']\n",
      "    Day 160: Top 3 leaders: [30, 1, 47], Sharpes: ['3.305', '2.975', '2.816']\n",
      "    Day 180: Top 3 leaders: [38, 43, 32], Sharpes: ['4.001', '2.645', '2.510']\n",
      "    Day 200: Top 3 leaders: [38, 32, 21], Sharpes: ['4.442', '3.119', '1.683']\n",
      "    Day 220: Top 3 leaders: [32, 38, 21], Sharpes: ['4.200', '3.790', '3.396']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 9 (Daily): Strat Vol: 6.81%, Mkt Vol: 11.69%, Ret_penalty: 0.6811, Sharpe: 0.7390, Adj Sharpe: 0.4396\n",
      "--- Starting Fold 10/20 (Days 2383 to 2619) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [10, 38, 21], Sharpes: ['2.884', '2.422', '2.292']\n",
      "    Day 20: Top 3 leaders: [10, 29, 36], Sharpes: ['2.280', '1.973', '1.816']\n",
      "    Day 40: Top 3 leaders: [29, 17, 15], Sharpes: ['2.157', '1.458', '1.438']\n",
      "    Day 60: Top 3 leaders: [17, 29, 46], Sharpes: ['2.687', '1.891', '1.444']\n",
      "    Day 80: Top 3 leaders: [28, 19, 12], Sharpes: ['-0.134', '-0.226', '-0.226']\n",
      "    Day 100: Top 3 leaders: [11, 23, 28], Sharpes: ['1.169', '-0.108', '-0.169']\n",
      "    Day 120: Top 3 leaders: [11, 10, 17], Sharpes: ['1.950', '0.760', '0.375']\n",
      "    Day 140: Top 3 leaders: [9, 16, 39], Sharpes: ['3.767', '3.729', '3.450']\n",
      "    Day 160: Top 3 leaders: [9, 43, 21], Sharpes: ['2.554', '2.152', '2.096']\n",
      "    Day 180: Top 3 leaders: [43, 28, 41], Sharpes: ['-0.080', '-0.155', '-0.211']\n",
      "    Day 200: Top 3 leaders: [46, 43, 3], Sharpes: ['1.849', '1.568', '1.337']\n",
      "    Day 220: Top 3 leaders: [3, 46, 43], Sharpes: ['3.227', '2.890', '2.565']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 10 (Daily): Strat Vol: 17.09%, Mkt Vol: 16.89%, Ret_penalty: 0.0000, Sharpe: 0.5691, Adj Sharpe: 0.5691\n",
      "--- Starting Fold 11/20 (Days 2620 to 2856) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [46, 13, 0], Sharpes: ['3.867', '3.398', '3.379']\n",
      "    Day 20: Top 3 leaders: [12, 45, 29], Sharpes: ['3.790', '3.564', '3.455']\n",
      "    Day 40: Top 3 leaders: [11, 45, 29], Sharpes: ['3.010', '3.004', '2.901']\n",
      "    Day 60: Top 3 leaders: [47, 46, 12], Sharpes: ['3.554', '2.449', '2.252']\n",
      "    Day 80: Top 3 leaders: [47, 30, 46], Sharpes: ['5.467', '4.702', '4.581']\n",
      "    Day 100: Top 3 leaders: [30, 46, 47], Sharpes: ['4.585', '4.366', '3.821']\n",
      "    Day 120: Top 3 leaders: [9, 49, 0], Sharpes: ['1.333', '1.212', '1.166']\n",
      "    Day 140: Top 3 leaders: [35, 26, 42], Sharpes: ['1.024', '0.932', '0.929']\n",
      "    Day 160: Top 3 leaders: [37, 26, 46], Sharpes: ['3.604', '2.917', '2.825']\n",
      "    Day 180: Top 3 leaders: [31, 18, 13], Sharpes: ['4.328', '4.242', '4.223']\n",
      "    Day 200: Top 3 leaders: [8, 16, 18], Sharpes: ['5.920', '5.832', '5.765']\n",
      "    Day 220: Top 3 leaders: [49, 6, 15], Sharpes: ['5.524', '4.905', '4.843']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 11 (Daily): Strat Vol: 8.30%, Mkt Vol: 9.95%, Ret_penalty: 0.1557, Sharpe: 1.6512, Adj Sharpe: 1.4287\n",
      "--- Starting Fold 12/20 (Days 2857 to 3093) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [6, 20, 10], Sharpes: ['4.528', '4.524', '4.445']\n",
      "    Day 20: Top 3 leaders: [3, 2, 1], Sharpes: ['3.574', '3.545', '3.437']\n",
      "    Day 40: Top 3 leaders: [2, 10, 24], Sharpes: ['2.445', '2.036', '1.997']\n",
      "    Day 60: Top 3 leaders: [44, 24, 46], Sharpes: ['4.251', '4.139', '4.091']\n",
      "    Day 80: Top 3 leaders: [24, 44, 48], Sharpes: ['3.118', '3.100', '2.916']\n",
      "    Day 100: Top 3 leaders: [42, 14, 16], Sharpes: ['3.200', '2.167', '1.720']\n",
      "    Day 120: Top 3 leaders: [42, 16, 10], Sharpes: ['3.105', '2.309', '2.173']\n",
      "    Day 140: Top 3 leaders: [28, 35, 32], Sharpes: ['4.197', '3.880', '3.832']\n",
      "    Day 160: Top 3 leaders: [36, 38, 0], Sharpes: ['7.049', '6.972', '6.888']\n",
      "    Day 180: Top 3 leaders: [45, 36, 32], Sharpes: ['5.707', '5.566', '5.409']\n",
      "    Day 200: Top 3 leaders: [11, 45, 21], Sharpes: ['4.910', '4.652', '4.618']\n",
      "    Day 220: Top 3 leaders: [34, 36, 21], Sharpes: ['6.599', '6.453', '6.384']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 12 (Daily): Strat Vol: 7.30%, Mkt Vol: 10.09%, Ret_penalty: 0.1133, Sharpe: 1.8076, Adj Sharpe: 1.6237\n",
      "--- Starting Fold 13/20 (Days 3094 to 3330) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [4, 40, 2], Sharpes: ['4.258', '3.217', '3.035']\n",
      "    Day 20: Top 3 leaders: [19, 15, 11], Sharpes: ['0.162', '0.066', '-0.140']\n",
      "    Day 40: Top 3 leaders: [31, 15, 27], Sharpes: ['3.127', '2.391', '1.879']\n",
      "    Day 60: Top 3 leaders: [31, 15, 32], Sharpes: ['1.953', '1.445', '0.818']\n",
      "    Day 80: Top 3 leaders: [31, 19, 47], Sharpes: ['4.568', '3.235', '3.203']\n",
      "    Day 100: Top 3 leaders: [12, 42, 47], Sharpes: ['3.426', '3.414', '3.047']\n",
      "    Day 120: Top 3 leaders: [7, 20, 19], Sharpes: ['3.528', '3.344', '3.155']\n",
      "    Day 140: Top 3 leaders: [19, 22, 35], Sharpes: ['4.434', '4.038', '3.894']\n",
      "    Day 160: Top 3 leaders: [20, 27, 28], Sharpes: ['0.257', '-0.301', '-0.325']\n",
      "    Day 180: Top 3 leaders: [28, 29, 30], Sharpes: ['-0.208', '-0.214', '-0.333']\n",
      "    Day 200: Top 3 leaders: [42, 28, 49], Sharpes: ['-0.092', '-0.158', '-0.216']\n",
      "    Day 220: Top 3 leaders: [21, 19, 18], Sharpes: ['1.634', '1.512', '1.366']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 13 (Daily): Strat Vol: 19.29%, Mkt Vol: 16.21%, Ret_penalty: 0.0000, Sharpe: 0.2576, Adj Sharpe: 0.2576\n",
      "--- Starting Fold 14/20 (Days 3331 to 3567) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [18, 43, 4], Sharpes: ['2.557', '2.389', '2.361']\n",
      "    Day 20: Top 3 leaders: [19, 10, 1], Sharpes: ['4.533', '4.525', '4.302']\n",
      "    Day 40: Top 3 leaders: [28, 5, 10], Sharpes: ['5.348', '5.342', '5.278']\n",
      "    Day 60: Top 3 leaders: [14, 44, 46], Sharpes: ['4.555', '4.225', '4.209']\n",
      "    Day 80: Top 3 leaders: [31, 47, 19], Sharpes: ['0.475', '-0.210', '-0.268']\n",
      "    Day 100: Top 3 leaders: [29, 47, 9], Sharpes: ['2.818', '2.478', '1.839']\n",
      "    Day 120: Top 3 leaders: [29, 32, 33], Sharpes: ['4.000', '3.415', '3.387']\n",
      "    Day 140: Top 3 leaders: [49, 7, 8], Sharpes: ['1.940', '1.656', '1.468']\n",
      "    Day 160: Top 3 leaders: [7, 8, 40], Sharpes: ['1.525', '1.398', '1.004']\n",
      "    Day 180: Top 3 leaders: [8, 14, 9], Sharpes: ['2.193', '2.147', '2.115']\n",
      "    Day 200: Top 3 leaders: [14, 17, 18], Sharpes: ['4.176', '2.614', '2.597']\n",
      "    Day 220: Top 3 leaders: [40, 19, 24], Sharpes: ['7.655', '7.502', '7.308']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 14 (Daily): Strat Vol: 9.15%, Mkt Vol: 11.79%, Ret_penalty: 0.4798, Sharpe: 1.3955, Adj Sharpe: 0.9431\n",
      "--- Starting Fold 15/20 (Days 3568 to 3804) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [19, 2, 33], Sharpes: ['6.544', '6.233', '6.150']\n",
      "    Day 20: Top 3 leaders: [30, 35, 37], Sharpes: ['5.822', '5.656', '5.552']\n",
      "    Day 40: Top 3 leaders: [22, 28, 7], Sharpes: ['-0.054', '-0.071', '-0.076']\n",
      "    Day 60: Top 3 leaders: [10, 32, 19], Sharpes: ['0.382', '0.299', '0.074']\n",
      "    Day 80: Top 3 leaders: [10, 26, 32], Sharpes: ['1.996', '1.631', '1.561']\n",
      "    Day 100: Top 3 leaders: [10, 2, 26], Sharpes: ['5.357', '5.060', '4.687']\n",
      "    Day 120: Top 3 leaders: [41, 9, 2], Sharpes: ['5.056', '3.914', '3.666']\n",
      "    Day 140: Top 3 leaders: [41, 9, 42], Sharpes: ['6.964', '5.015', '4.774']\n",
      "    Day 160: Top 3 leaders: [43, 42, 45], Sharpes: ['6.534', '6.506', '6.425']\n",
      "    Day 180: Top 3 leaders: [3, 42, 1], Sharpes: ['1.911', '1.798', '1.735']\n",
      "    Day 200: Top 3 leaders: [3, 25, 31], Sharpes: ['0.886', '0.359', '0.255']\n",
      "    Day 220: Top 3 leaders: [16, 3, 39], Sharpes: ['3.926', '3.017', '2.920']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 15 (Daily): Strat Vol: 29.66%, Mkt Vol: 26.01%, Ret_penalty: 0.0000, Sharpe: 0.8540, Adj Sharpe: 0.8540\n",
      "--- Starting Fold 16/20 (Days 3805 to 4041) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [16, 39, 32], Sharpes: ['3.405', '2.807', '2.516']\n",
      "    Day 20: Top 3 leaders: [35, 25, 9], Sharpes: ['5.060', '4.624', '4.572']\n",
      "    Day 40: Top 3 leaders: [33, 42, 31], Sharpes: ['3.249', '2.944', '2.905']\n",
      "    Day 60: Top 3 leaders: [37, 23, 33], Sharpes: ['2.574', '2.521', '2.441']\n",
      "    Day 80: Top 3 leaders: [23, 37, 6], Sharpes: ['3.533', '3.403', '3.164']\n",
      "    Day 100: Top 3 leaders: [47, 20, 38], Sharpes: ['4.219', '4.034', '3.994']\n",
      "    Day 120: Top 3 leaders: [8, 38, 47], Sharpes: ['3.222', '2.765', '2.624']\n",
      "    Day 140: Top 3 leaders: [8, 9, 4], Sharpes: ['3.205', '3.148', '2.887']\n",
      "    Day 160: Top 3 leaders: [3, 28, 6], Sharpes: ['4.143', '3.771', '3.746']\n",
      "    Day 180: Top 3 leaders: [3, 44, 23], Sharpes: ['3.283', '3.169', '3.132']\n",
      "    Day 200: Top 3 leaders: [41, 44, 47], Sharpes: ['1.704', '0.810', '0.666']\n",
      "    Day 220: Top 3 leaders: [2, 41, 47], Sharpes: ['3.928', '3.513', '3.049']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 16 (Daily): Strat Vol: 11.66%, Mkt Vol: 12.50%, Ret_penalty: 0.0000, Sharpe: 1.9775, Adj Sharpe: 1.9775\n",
      "--- Starting Fold 17/20 (Days 4042 to 4278) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [41, 31, 30], Sharpes: ['2.846', '2.575', '2.356']\n",
      "    Day 20: Top 3 leaders: [8, 36, 31], Sharpes: ['2.858', '2.782', '2.771']\n",
      "    Day 40: Top 3 leaders: [31, 25, 36], Sharpes: ['-0.163', '-0.260', '-0.284']\n",
      "    Day 60: Top 3 leaders: [21, 18, 16], Sharpes: ['0.322', '-0.072', '-0.168']\n",
      "    Day 80: Top 3 leaders: [7, 21, 8], Sharpes: ['2.612', '2.328', '0.888']\n",
      "    Day 100: Top 3 leaders: [21, 7, 19], Sharpes: ['1.125', '0.987', '0.126']\n",
      "    Day 120: Top 3 leaders: [7, 21, 22], Sharpes: ['1.667', '0.063', '0.029']\n",
      "    Day 140: Top 3 leaders: [1, 31, 29], Sharpes: ['-0.037', '-0.041', '-0.054']\n",
      "    Day 160: Top 3 leaders: [22, 41, 7], Sharpes: ['1.481', '0.548', '0.507']\n",
      "    Day 180: Top 3 leaders: [38, 22, 41], Sharpes: ['2.241', '2.101', '2.050']\n",
      "    Day 200: Top 3 leaders: [38, 22, 5], Sharpes: ['1.433', '1.252', '1.096']\n",
      "    Day 220: Top 3 leaders: [22, 20, 1], Sharpes: ['0.423', '-0.072', '-0.079']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 17 (Daily): Strat Vol: 26.97%, Mkt Vol: 23.74%, Ret_penalty: 0.0000, Sharpe: -0.2975, Adj Sharpe: -0.2975\n",
      "--- Starting Fold 18/20 (Days 4279 to 4515) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [22, 1, 20], Sharpes: ['0.083', '-0.090', '-0.133']\n",
      "    Day 20: Top 3 leaders: [49, 38, 28], Sharpes: ['2.240', '1.882', '1.830']\n",
      "    Day 40: Top 3 leaders: [7, 49, 5], Sharpes: ['1.439', '0.995', '0.833']\n",
      "    Day 60: Top 3 leaders: [12, 39, 6], Sharpes: ['2.239', '1.870', '1.847']\n",
      "    Day 80: Top 3 leaders: [12, 49, 48], Sharpes: ['2.979', '2.226', '2.169']\n",
      "    Day 100: Top 3 leaders: [48, 7, 12], Sharpes: ['3.037', '2.515', '2.327']\n",
      "    Day 120: Top 3 leaders: [37, 46, 7], Sharpes: ['1.913', '1.656', '1.349']\n",
      "    Day 140: Top 3 leaders: [10, 11, 43], Sharpes: ['3.822', '3.736', '3.733']\n",
      "    Day 160: Top 3 leaders: [14, 10, 11], Sharpes: ['3.917', '3.493', '3.390']\n",
      "    Day 180: Top 3 leaders: [14, 1, 49], Sharpes: ['5.204', '4.839', '4.604']\n",
      "    Day 200: Top 3 leaders: [0, 1, 49], Sharpes: ['2.158', '1.570', '1.516']\n",
      "    Day 220: Top 3 leaders: [22, 26, 47], Sharpes: ['-0.609', '-0.778', '-1.033']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 18 (Daily): Strat Vol: 12.56%, Mkt Vol: 14.79%, Ret_penalty: 0.0050, Sharpe: 0.5763, Adj Sharpe: 0.5734\n",
      "--- Starting Fold 19/20 (Days 4516 to 4752) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [34, 45, 22], Sharpes: ['1.136', '-0.561', '-0.676']\n",
      "    Day 20: Top 3 leaders: [34, 38, 45], Sharpes: ['3.181', '2.010', '1.946']\n",
      "    Day 40: Top 3 leaders: [34, 37, 32], Sharpes: ['5.074', '4.628', '4.522']\n",
      "    Day 60: Top 3 leaders: [29, 42, 4], Sharpes: ['4.963', '4.874', '4.745']\n",
      "    Day 80: Top 3 leaders: [43, 41, 4], Sharpes: ['5.064', '4.800', '4.649']\n",
      "    Day 100: Top 3 leaders: [35, 43, 31], Sharpes: ['4.243', '4.080', '3.977']\n",
      "    Day 120: Top 3 leaders: [43, 49, 23], Sharpes: ['2.252', '2.076', '1.968']\n",
      "    Day 140: Top 3 leaders: [48, 14, 36], Sharpes: ['2.039', '1.989', '1.359']\n",
      "    Day 160: Top 3 leaders: [0, 9, 14], Sharpes: ['2.929', '2.637', '2.533']\n",
      "    Day 180: Top 3 leaders: [44, 34, 48], Sharpes: ['5.590', '5.383', '5.029']\n",
      "    Day 200: Top 3 leaders: [40, 9, 6], Sharpes: ['1.225', '1.119', '1.110']\n",
      "    Day 220: Top 3 leaders: [39, 11, 27], Sharpes: ['0.515', '0.422', '0.342']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 19 (Daily): Strat Vol: 9.75%, Mkt Vol: 12.39%, Ret_penalty: 0.3922, Sharpe: 2.2499, Adj Sharpe: 1.6160\n",
      "--- Starting Fold 20/20 (Days 4753 to 4989) ---\n",
      "  Iterating daily and re-ranking leaders...\n",
      "    Day 0: Top 3 leaders: [25, 41, 27], Sharpes: ['1.514', '1.503', '1.424']\n",
      "    Day 20: Top 3 leaders: [7, 36, 39], Sharpes: ['2.762', '2.643', '2.499']\n",
      "    Day 40: Top 3 leaders: [21, 29, 36], Sharpes: ['3.486', '3.307', '3.264']\n",
      "    Day 60: Top 3 leaders: [22, 0, 13], Sharpes: ['2.340', '2.264', '2.083']\n",
      "    Day 80: Top 3 leaders: [22, 13, 8], Sharpes: ['1.615', '1.126', '1.058']\n",
      "    Day 100: Top 3 leaders: [22, 8, 13], Sharpes: ['0.054', '-0.176', '-0.226']\n",
      "    Day 120: Top 3 leaders: [11, 48, 16], Sharpes: ['1.189', '0.288', '0.038']\n",
      "    Day 140: Top 3 leaders: [30, 25, 40], Sharpes: ['-0.090', '-0.111', '-0.123']\n",
      "    Day 160: Top 3 leaders: [26, 23, 35], Sharpes: ['1.529', '1.422', '1.364']\n",
      "    Day 180: Top 3 leaders: [42, 48, 4], Sharpes: ['3.998', '3.822', '2.931']\n",
      "    Day 200: Top 3 leaders: [11, 38, 15], Sharpes: ['4.786', '4.614', '4.458']\n",
      "    Day 220: Top 3 leaders: [38, 32, 11], Sharpes: ['4.050', '3.987', '3.629']\n",
      "  Fold iteration complete. Scoring fold...\n",
      "  Fold 20 (Daily): Strat Vol: 19.17%, Mkt Vol: 16.28%, Ret_penalty: 0.8665, Sharpe: 0.0096, Adj Sharpe: 0.0051\n",
      "\n",
      "--- CV Finished ---\n",
      "Mean Ensembled CV Score (Daily Re-ranking): 0.5722, std: 0.6835\n",
      "\n",
      "--- Overall OOS Performance (Daily Re-ranking) ---\n",
      "  Fold 20 (Daily): Strat Vol: 16.43%, Mkt Vol: 17.49%, Ret_penalty: 0.0379, Sharpe: 0.4627, Adj Sharpe: 0.4458\n",
      " Overall Ensembled Score: 0.4458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.4457566789306708)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def evaluate(excessarg: int) -> float:\n",
    "    \"\"\"\n",
    "    Main evaluation function for FunSearch. It loads the data\n",
    "    and runs the solver which performs cross-validation.\n",
    "    \"\"\"\n",
    "    full_train_df = pl.read_csv(TRAIN_DATA_PATH)\n",
    "    # Use a slice of data for faster evaluation runs during development\n",
    "    df_raw = full_train_df.slice(4000)\n",
    "    print(df_raw.shape)\n",
    "\n",
    "    #fill nulls in df with mean\n",
    "    df = df_raw.with_columns(\n",
    "        # Select all numeric columns for the operation\n",
    "        pl.selectors.numeric()\n",
    "          # Step 1: Attempt to fill with the rolling mean of each respective column\n",
    "          .fill_null(\n",
    "              pl.selectors.numeric().rolling_mean(window_size=5, min_periods=1)\n",
    "          )\n",
    "          # Step 2: Fall back to the global column mean for any remaining nulls\n",
    "          #.fill_null(strategy='mean')\n",
    "    )\n",
    "    df = df.with_columns(\n",
    "    pl.col(\"date_id\").cast(pl.Int64)\n",
    "    )\n",
    "    \n",
    "    weekday_df = add_weekday_column(SPY_DATA_PATH)\n",
    "    print(\"\\n--- Joining weekday feature onto sliced data ---\")\n",
    "    # Join the weekday information onto the sliced training data.\n",
    "    # A 'left' join ensures we keep all rows from the original `df`.\n",
    "    df_with_features = df.join(weekday_df, on=\"date_id\", how=\"left\")\n",
    "    # print(\"DataFrame after join:\")\n",
    "    # print(df_with_features.shape)\n",
    "    return solve(df_with_features)\n",
    "  \n",
    "def add_weekday_column(input_csv_path: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a CSV file, adds a 'weekday' column based on the 'Date' column,\n",
    "    and saves the result to a new CSV file.\n",
    "\n",
    "    Args:\n",
    "        input_csv_path (str): The path to the source CSV file.\n",
    "        output_csv_path (str): The path where the output CSV will be saved.\n",
    "    \"\"\"\n",
    "    # Read the CSV file into a Polars DataFrame\n",
    "    df = pl.read_csv(input_csv_path)\n",
    "\n",
    "    # Add a new column named 'weekday'\n",
    "    # 1. Select the 'Date' column.\n",
    "    # 2. Convert the string representation to a proper date type.\n",
    "    # 3. Use the .dt.weekday() function to get the day of the week (Monday=1, Sunday=7).\n",
    "    # 4. Alias the new expression to 'weekday'.\n",
    "    df_with_weekday = df.with_columns(\n",
    "        pl.col(\"Date\").str.to_date().dt.weekday().alias(\"weekday\")\n",
    "    )\n",
    "\n",
    "    # Print the transformed DataFrame to the console to show the result\n",
    "    returned_df = df_with_weekday.select([\"date_id\", \"weekday\"])\n",
    "    return returned_df\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='.*XGBoost is not compiled with CUDA support.*')\n",
    "\n",
    "evaluate(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
